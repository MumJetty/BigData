{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mo.1-1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (문제 ①) iris 데이터셋을 불러와, Sepal.Width 컬럼에 대해 Sepal.Width의 평균값을 기준으로 3배 표준편차 이상으로 떨어진 값들의 합을 구하여라. \n",
    "\n",
    "import pandas as pd\n",
    "exam1=pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\01회\\iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sepal_width 별도 저장 \n",
    "sepal_width=exam1['Sepal.Width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> sepal_width 평균 기준 3배 표준편차 이상 떨어진 데이터 추출 \n",
    "# sepal_width의 평균 | sepal_width의 표준편차 \n",
    "avg=sepal_width.mean()\n",
    "sd=sepal_width.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상한과 하한 (3배 표준편차 기준)\n",
    "upp=avg+3*sd\n",
    "low=avg-3*sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> sepal_width 평균 기준 3배 표준편차 이상 벗어날 조건\n",
    "# 하한 보다 작고 상한 보다 큼 \n",
    "cond=(sepal_width<low)|(sepal_width>upp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당 \n",
    "# 떨어진 값들의 합 \n",
    "result=sepal_width[cond].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력 \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Series name: Sepal.Width\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "150 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 1.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 요약 정보 확인 \n",
    "print(sepal_width.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    150.000000\n",
      "mean       3.057333\n",
      "std        0.435866\n",
      "min        2.000000\n",
      "25%        2.800000\n",
      "50%        3.000000\n",
      "75%        3.300000\n",
      "max        4.400000\n",
      "Name: Sepal.Width, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 기초통계량 확인 \n",
    "print(sepal_width.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Sepal.Length  150 non-null    float64\n",
      " 1   Sepal.Width   150 non-null    float64\n",
      " 2   Petal.Length  150 non-null    float64\n",
      " 3   Petal.Width   150 non-null    float64\n",
      " 4   Species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 요약 정보 확인 \n",
    "print(exam1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.057333      3.758000     1.199333\n",
      "std        0.828066     0.435866      1.765298     0.762238\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n"
     ]
    }
   ],
   "source": [
    "# 기초통계량 확인 \n",
    "print(exam1.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mo. 1-1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (문제 ②) mtcars1 데이터셋을 불러와, disp 컬럼에 대해서 순위를 부여한 후, 1위부터 20위까지의 값들의 표준편차를 구하고 소수점 셋째자리에서 반올림하여 나타내어라. (단, 동점은 동일한 순위를 부여하되 상위 등수를 기준으로 하며 최댓값을 1위로 함) \n",
    "\n",
    "import pandas as pd\n",
    "exam2=pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\01회\\mtcars1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disp 컬럼 별도 저장 \n",
    "disp=exam2['disp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32 entries, 0 to 31\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   mpg     32 non-null     float64\n",
      " 1   cyl     32 non-null     int64  \n",
      " 2   disp    32 non-null     float64\n",
      " 3   hp      32 non-null     int64  \n",
      " 4   drat    32 non-null     float64\n",
      " 5   wt      32 non-null     float64\n",
      " 6   qsec    32 non-null     float64\n",
      " 7   vs      32 non-null     int64  \n",
      " 8   am      32 non-null     int64  \n",
      " 9   gear    32 non-null     int64  \n",
      " 10  carb    32 non-null     int64  \n",
      "dtypes: float64(5), int64(6)\n",
      "memory usage: 2.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 요약 정보 확인 \n",
    "print(exam2.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             mpg        cyl        disp          hp       drat         wt  \\\n",
      "count  32.000000  32.000000   32.000000   32.000000  32.000000  32.000000   \n",
      "mean   20.090625   6.187500  230.721875  146.687500   3.596563   3.217250   \n",
      "std     6.026948   1.785922  123.938694   68.562868   0.534679   0.978457   \n",
      "min    10.400000   4.000000   71.100000   52.000000   2.760000   1.513000   \n",
      "25%    15.425000   4.000000  120.825000   96.500000   3.080000   2.581250   \n",
      "50%    19.200000   6.000000  196.300000  123.000000   3.695000   3.325000   \n",
      "75%    22.800000   8.000000  326.000000  180.000000   3.920000   3.610000   \n",
      "max    33.900000   8.000000  472.000000  335.000000   4.930000   5.424000   \n",
      "\n",
      "            qsec         vs         am       gear     carb  \n",
      "count  32.000000  32.000000  32.000000  32.000000  32.0000  \n",
      "mean   17.848750   0.437500   0.406250   3.687500   2.8125  \n",
      "std     1.786943   0.504016   0.498991   0.737804   1.6152  \n",
      "min    14.500000   0.000000   0.000000   3.000000   1.0000  \n",
      "25%    16.892500   0.000000   0.000000   3.000000   2.0000  \n",
      "50%    17.710000   0.000000   0.000000   4.000000   2.0000  \n",
      "75%    18.900000   1.000000   1.000000   4.000000   4.0000  \n",
      "max    22.900000   1.000000   1.000000   5.000000   8.0000  \n"
     ]
    }
   ],
   "source": [
    "# 기초통계량 확인 \n",
    "print(exam2.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disp 순위 부여\n",
    "rank=disp.rank(method='min', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1위부터 20위까지 값\n",
    "rank20=disp[rank<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당 \n",
    "# 반올림 소수점 셋째자리에서(둘째자리까지 남기고), 표준편차 구하기 \n",
    "result=round(rank20.std(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.47\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력 \n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mo. 1-1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (문제 ③) Cars93 데이터셋을 불러와, '전체 레코드 수', '결측치가 있는 컬럼의 수', '전체 결측치 수', '결측치가 10개 이상인 컬럼들의 결측치가 있는 레코드만 삭제한 후의 전체 레코드 수'와 '두 개 이상의 컬럼이 동시에 결측인 레코드의 행번호들의 합'을 구한 후 모두 합하여라.  \n",
    "\n",
    "import pandas as pd\n",
    "exam3=pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\01회\\Cars93.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93 entries, 0 to 92\n",
      "Data columns (total 28 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Manufacturer        93 non-null     object \n",
      " 1   Model               93 non-null     object \n",
      " 2   Type                93 non-null     object \n",
      " 3   Min_Price           93 non-null     float64\n",
      " 4   Price               84 non-null     float64\n",
      " 5   Max_Price           93 non-null     float64\n",
      " 6   MPG_city            93 non-null     int64  \n",
      " 7   MPG_highway         93 non-null     int64  \n",
      " 8   AirBags             93 non-null     object \n",
      " 9   DriveTrain          93 non-null     object \n",
      " 10  Cylinders           93 non-null     object \n",
      " 11  EngineSize          93 non-null     float64\n",
      " 12  Horsepower          93 non-null     int64  \n",
      " 13  RPM                 89 non-null     float64\n",
      " 14  Rev_per_mile        93 non-null     int64  \n",
      " 15  Man_trans_avail     93 non-null     object \n",
      " 16  Fuel_tank_capacity  93 non-null     float64\n",
      " 17  Passengers          93 non-null     int64  \n",
      " 18  Length              93 non-null     int64  \n",
      " 19  Wheelbase           93 non-null     int64  \n",
      " 20  Width               93 non-null     int64  \n",
      " 21  Turn_circle         80 non-null     float64\n",
      " 22  Rear_seat_room      91 non-null     float64\n",
      " 23  Luggage_room        82 non-null     float64\n",
      " 24  Weight              93 non-null     int64  \n",
      " 25  Origin              93 non-null     object \n",
      " 26  Unnamed: 26         93 non-null     int64  \n",
      " 27  Make                93 non-null     object \n",
      "dtypes: float64(9), int64(10), object(9)\n",
      "memory usage: 20.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 요약 정보 확인 \n",
    "print(exam3.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Min_Price      Price  Max_Price   MPG_city  MPG_highway  EngineSize  \\\n",
      "count  93.000000  84.000000  93.000000  93.000000    93.000000   93.000000   \n",
      "mean   17.125806  19.047619  21.898925  22.365591    29.086022    2.667742   \n",
      "std     8.746029   9.696608  11.030457   5.619812     5.331726    1.037363   \n",
      "min     6.700000   7.400000   7.900000  15.000000    20.000000    1.000000   \n",
      "25%    10.800000  12.025000  14.700000  18.000000    26.000000    1.800000   \n",
      "50%    14.700000  16.550000  19.600000  21.000000    28.000000    2.400000   \n",
      "75%    20.300000  21.800000  25.300000  25.000000    31.000000    3.300000   \n",
      "max    45.400000  61.900000  80.000000  46.000000    50.000000    5.700000   \n",
      "\n",
      "       Horsepower          RPM  Rev_per_mile  Fuel_tank_capacity  Passengers  \\\n",
      "count   93.000000    89.000000     93.000000           93.000000   93.000000   \n",
      "mean   143.827957  5277.528090   2341.408602           16.664516    5.086022   \n",
      "std     52.374410   602.928989    598.459676            3.279370    1.038979   \n",
      "min     55.000000  3800.000000    825.000000            9.200000    2.000000   \n",
      "25%    103.000000  4800.000000   1980.000000           14.500000    4.000000   \n",
      "50%    140.000000  5200.000000   2340.000000           16.400000    5.000000   \n",
      "75%    170.000000  5750.000000   2595.000000           18.800000    6.000000   \n",
      "max    300.000000  6500.000000   4305.000000           27.000000    8.000000   \n",
      "\n",
      "           Length   Wheelbase      Width  Turn_circle  Rear_seat_room  \\\n",
      "count   93.000000   93.000000  93.000000     80.00000       91.000000   \n",
      "mean   183.204301  103.989247  69.376344     39.10000       27.829670   \n",
      "std     14.602382    7.389026   3.778986      3.29787        2.989072   \n",
      "min    141.000000   85.000000  60.000000     32.00000       19.000000   \n",
      "25%    174.000000   98.000000  67.000000     37.00000       26.000000   \n",
      "50%    183.000000  103.000000  69.000000     39.00000       27.500000   \n",
      "75%    192.000000  110.000000  72.000000     42.00000       30.000000   \n",
      "max    219.000000  124.000000  78.000000     45.00000       36.000000   \n",
      "\n",
      "       Luggage_room       Weight  Unnamed: 26  \n",
      "count     82.000000    93.000000    93.000000  \n",
      "mean      13.890244  3081.505376    46.000000  \n",
      "std        2.997967   704.756104    26.990739  \n",
      "min        6.000000   713.000000     0.000000  \n",
      "25%       12.000000  2620.000000    23.000000  \n",
      "50%       14.000000  3040.000000    46.000000  \n",
      "75%       15.000000  3560.000000    69.000000  \n",
      "max       22.000000  6022.000000    92.000000  \n"
     ]
    }
   ],
   "source": [
    "# 기초통계량 확인 \n",
    "print(exam3.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case1. | 전체 레코드 수 \n",
    "case1=exam3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "# 행 수(셰입0) | 열 수(셰입1) \n",
    "print(exam3.shape[0])\n",
    "print(exam3.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### case2. | -> 결측치가 있는 컬럼의 수 \n",
    "# ; 결측치 조회 및 합 했을 때(이즈앤애이&썸), 0이 아닌 것의 합(썸)\n",
    "case2=sum(exam3.isna().sum() !=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case3. | 전체 결측치 수 , 썸의썸 \n",
    "case3=sum(exam3.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case4. 결측치가 10개 이상인 컬럼들의, 결측치가 있는 레코드만 삭제한 후의, 전체 레코드 수\n",
    "# 결측치 수가 10개 이상인 컬럼명을 colnm_10over에 할당 | ; 쩜 컬럼이 있음  \n",
    "colnm_10over=exam3.columns[exam3.isna().sum()>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#그 중에서 결측치가 없는 경우의 전체 레코드 수 \n",
    "# ; 카피는 사본 생성 | 결측치 row 삭제 후 행수 세기 \n",
    "# ; sub1 안에가 컬럼10오버고, 컬럼10오버 안에가 컬럼확인한 것이므로, len으로 레코드수 확인 가능 \n",
    "sub1=exam3[colnm_10over].copy()\n",
    "case4=len(sub1.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### case5. | 두개 이상의 컬럼이 동시에 결측인 레코드의 행 번호들의 합 \n",
    "# -> 결측치의 수가 2개 이상인 행 인덱스를 rownm_2over에 할당 \n",
    "# (; 인덱스는 리스트 중 특정 원소 몇번째 | axis=1은 컬럼 drop 시 | 결측 컬럼이 2개 이상인 행을 지정하는 것 )\n",
    "rownm_2over=exam3.index[exam3.isna().sum(axis=1) >=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행 번호를 리스트로 반환한 수 합함 \n",
    "sub2=list(rownm_2over)\n",
    "case5=sum(sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "407"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 15, 18, 39, 55, 56, 65, 69, 83]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당 \n",
    "result=case1+case2+case3+case4+case5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력 \n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mo. 1-2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [작업형 제2유형] \n",
    "\n",
    "# (문제 Ⅱ) 아래는 타이타닉호의 탑승자들의 생존과 관련한 데이터이다. 주어진 데이터를 이용하여 예측 모형을 만들고 아래에 따라 CSV 파일을 생성하시오. \n",
    "# (문제 조건) (\"분류 알고리즘 사용\") 성능이 우수한 예측모형을 구축하기 위해서는 적절한 데이터 전처리, Feature Engineering, \"분류 알고리즘\" 사용, 초매개변수 최적화, 모형 앙상블 등이 수반되어야 한다. \n",
    "# (제출형식) ID | survived \n",
    "\n",
    "# Ⅰ.데이터셋 불러오기  Ⅱ.데이터셋 확인하기  Ⅲ.데이터셋 전처리  Ⅳ.모델학습  Ⅴ.결과제출  Ⅵ.채점모델평가  \n",
    "# \"Ⅲ.데이터셋 전처리\" - (1)불필요한 컬럼 삭제  (2)결측치 처리  (3)카테고리형 컬럼 전처리  (4)수치형 컬럼 전처리 \n",
    "# (5)데이터 분할  (6)인코딩  (7)스케일링  (8)입력 데이터셋 준비  \n",
    "\n",
    "# \" 타이타닉 \" \n",
    "# (Ⅰ.데이터셋 불러오기) Step1. | 데이터셋 불러오기 \n",
    "\n",
    "import pandas as pd \n",
    "X_train = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\01회\\titanic3_X_train.csv') \n",
    "X_test = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\01회\\titanic3_X_test.csv')\n",
    "y_train = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\01회\\titanic3_y_train.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  pclass      name   sex   age  sibsp  parch             ticket    fare  \\\n",
      "0   1       3  Sdy*****  male   NaN      0      0             349222  7.8958   \n",
      "1   2       3  Pel*****  male  25.0      0      0  STON/O 2. 3101291  7.9250   \n",
      "2   3       3  Kar*****  male  22.0      0      0             350060  7.5208   \n",
      "3   4       3  Saa*****  male   NaN      0      0               2676  7.2250   \n",
      "4   5       3  Cor*****  male  19.0      0      0             349231  7.8958   \n",
      "\n",
      "  cabin embarked  \n",
      "0   NaN        S  \n",
      "1   NaN        S  \n",
      "2   NaN        S  \n",
      "3   NaN        C  \n",
      "4   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# (Ⅱ.데이터셋 확인하기) Step2. | 데이터셋 확인하기 \n",
    "\n",
    "print(X_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID  pclass      name     sex   age  sibsp  parch    ticket      fare  \\\n",
      "0  786       1  All*****  female   2.0      1      2    113781  151.5500   \n",
      "1  787       1  And*****    male  39.0      0      0    112050    0.0000   \n",
      "2  788       1  Bau*****    male   NaN      0      0  PC 17318   25.9250   \n",
      "3  789       1  Bax*****    male  24.0      0      1  PC 17558  247.5208   \n",
      "4  790       1  Bea*****    male  36.0      0      0     13050   75.2417   \n",
      "\n",
      "     cabin embarked  \n",
      "0  C22 C26        S  \n",
      "1      A36        S  \n",
      "2      NaN        S  \n",
      "3  B58 B60        C  \n",
      "4       C6        C  \n"
     ]
    }
   ],
   "source": [
    "print(X_test.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  survived\n",
      "0   1         0\n",
      "1   2         0\n",
      "2   3         0\n",
      "3   4         0\n",
      "4   5         0\n"
     ]
    }
   ],
   "source": [
    "print(y_train.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785 entries, 0 to 784\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   ID        785 non-null    int64  \n",
      " 1   pclass    785 non-null    int64  \n",
      " 2   name      785 non-null    object \n",
      " 3   sex       785 non-null    object \n",
      " 4   age       628 non-null    float64\n",
      " 5   sibsp     785 non-null    int64  \n",
      " 6   parch     785 non-null    int64  \n",
      " 7   ticket    785 non-null    object \n",
      " 8   fare      784 non-null    float64\n",
      " 9   cabin     171 non-null    object \n",
      " 10  embarked  784 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 67.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Step 2-2. | 데이터셋 요약 정보 확인 ; 오브젝트는 문자형임\n",
    "\n",
    "print(X_train.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 524 entries, 0 to 523\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   ID        524 non-null    int64  \n",
      " 1   pclass    524 non-null    int64  \n",
      " 2   name      524 non-null    object \n",
      " 3   sex       524 non-null    object \n",
      " 4   age       418 non-null    float64\n",
      " 5   sibsp     524 non-null    int64  \n",
      " 6   parch     524 non-null    int64  \n",
      " 7   ticket    524 non-null    object \n",
      " 8   fare      524 non-null    float64\n",
      " 9   cabin     124 non-null    object \n",
      " 10  embarked  523 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 45.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X_test.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785 entries, 0 to 784\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   ID        785 non-null    int64\n",
      " 1   survived  785 non-null    int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 12.4 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(y_train.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ID      pclass         age       sibsp       parch        fare\n",
      "count  785.000000  785.000000  628.000000  785.000000  785.000000  784.000000\n",
      "mean   393.000000    2.296815   30.292994    0.501911    0.357962   33.454697\n",
      "std    226.754272    0.835929   14.660563    1.051146    0.781166   52.251342\n",
      "min      1.000000    1.000000    0.330000    0.000000    0.000000    0.000000\n",
      "25%    197.000000    2.000000   21.000000    0.000000    0.000000    7.895800\n",
      "50%    393.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%    589.000000    3.000000   39.250000    1.000000    0.000000   30.771850\n",
      "max    785.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "# Step 2-3. | 기초통계량 확인 \n",
    "\n",
    "print(X_train.describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ID      pclass         age       sibsp       parch       fare\n",
      "count   524.000000  524.000000  418.000000  524.000000  524.000000  524.00000\n",
      "mean   1047.500000    2.291985   29.262368    0.494275    0.425573   33.05726\n",
      "std     151.410039    0.841475   14.028790    1.028265    0.977859   51.06143\n",
      "min     786.000000    1.000000    0.170000    0.000000    0.000000    0.00000\n",
      "25%     916.750000    1.750000   21.000000    0.000000    0.000000    7.91770\n",
      "50%    1047.500000    3.000000   28.000000    0.000000    0.000000   14.45830\n",
      "75%    1178.250000    3.000000   37.750000    1.000000    0.000000   31.38750\n",
      "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.32920\n"
     ]
    }
   ],
   "source": [
    "print(X_test.describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ID    survived\n",
      "count  785.000000  785.000000\n",
      "mean   393.000000    0.382166\n",
      "std    226.754272    0.486227\n",
      "min      1.000000    0.000000\n",
      "25%    197.000000    0.000000\n",
      "50%    393.000000    0.000000\n",
      "75%    589.000000    1.000000\n",
      "max    785.000000    1.000000\n"
     ]
    }
   ],
   "source": [
    "print(y_train.describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Ⅲ.데이터셋 전처리) @ Step3. 데이터셋 전처리 \n",
    "\n",
    "# Step3-1. (1)불필요한 컬럼 삭제 : 데이터셋으로부터 ID, name 컬럼을 삭제한다.  \n",
    "# ID컬럼은 탑승자에 대한 고유 정보로 key 역할로 모델에는 불필요함 \n",
    "\n",
    "# 결과 제출 시에는 X_test의 ID컬럼이 필요하기 때문에 별도 저장 \n",
    "ID = X_test['ID'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name은 텍스트 전처리 등의 방법으로 분석 가능하기도 하지만 편의상 제외 \n",
    "\n",
    "# 데이터들에서 ID, name 컬럼 삭제 \n",
    "\n",
    "X_train = X_train.drop(columns = ['ID' , 'name']) \n",
    "\n",
    "X_test = X_test.drop(columns = ['ID' , 'name']) \n",
    "\n",
    "y_train = y_train.drop(columns = 'ID') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass        0\n",
       "sex           0\n",
       "age         157\n",
       "sibsp         0\n",
       "parch         0\n",
       "ticket        0\n",
       "fare          1\n",
       "cabin       614\n",
       "embarked      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3-2. (2)결측치 처리 \n",
    "# : Train, Test 양쪽의 결측치를 확인하고 결측치의 수, survived와의 상관관계 등을 기준으로 열 또는 행을 삭제하고 cabin 컬럼은 최다빈도를 가지는 레이블 값으로 대치한다. \n",
    "\n",
    "# 결측치 확인 \n",
    "X_train.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass        0\n",
       "sex           0\n",
       "age         106\n",
       "sibsp         0\n",
       "parch         0\n",
       "ticket        0\n",
       "fare          0\n",
       "cabin       400\n",
       "embarked      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인 \n",
    "X_test.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>524 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass    sex    age  sibsp  parch  ticket   fare  cabin  embarked\n",
       "0     False  False  False  False  False   False  False  False     False\n",
       "1     False  False  False  False  False   False  False  False     False\n",
       "2     False  False   True  False  False   False  False   True     False\n",
       "3     False  False  False  False  False   False  False  False     False\n",
       "4     False  False  False  False  False   False  False  False     False\n",
       "..      ...    ...    ...    ...    ...     ...    ...    ...       ...\n",
       "519   False  False  False  False  False   False  False   True     False\n",
       "520   False  False   True  False  False   False  False   True     False\n",
       "521   False  False  False  False  False   False  False   True     False\n",
       "522   False  False  False  False  False   False  False   True     False\n",
       "523   False  False  False  False  False   False  False   True     False\n",
       "\n",
       "[524 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 참고. 썸을 안 쳤을 때는 이렇게 나옴 \n",
    "X_test.isna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age 컬럼 (train 157, test 106 결측) \n",
    "# age는 탑승자의 나이를 의미하고, survived와 상관관계가 낮으므로 컬럼을 삭제 \n",
    "\n",
    "# 결측일 조건 \n",
    "cond_na = X_train['age'].isna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=-0.03894154189837849, pvalue=0.32990878593933864)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 피어슨 상관계수 | pearsonr( , ) = (상관계수, p-Value) | 유의수준 5%에서 귀무가설 기각 \n",
    "# ; 여기서 p-Value가 0.05 보다 크므로 유의하지 않다. | 상관관계도 적은데다가 음수 \n",
    "# ; 물결 '~'는 '포함되어있지않으면'. \n",
    "\n",
    "from scipy.stats import pearsonr \n",
    "\n",
    "pearsonr(y_train['survived'][~cond_na], X_train['age'][~cond_na]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완료 후 age 컬럼을 삭제 \n",
    "# drop에서 컬럼 날릴 때 axis=1 | drop에서 row 날릴 때 axis=0 \n",
    "\n",
    "X_train = X_train.drop('age', axis=1) \n",
    "X_test = X_test.drop('age', axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fare 컬럼 (train 1 결측) \n",
    "# ; fare는 티켓요금을 의미하고 train에만 결측치가 1개 존재하므로 레코드를 삭제함 \n",
    "\n",
    "# 결측일 조건 \n",
    "cond_na = X_train['fare'].isna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행 삭제 \n",
    "# 결측이 아닌 걸로 정의 \n",
    "\n",
    "X_train = X_train[~cond_na] \n",
    "y_train = y_train[~cond_na] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cabin 컬럼 (train 614, test 400 결측)\n",
    "# cabin은 선실번호를 의미하고 train은 레코드의 78%, test는 레코드의 76%가 결측이므로 컬럼을 삭제 \n",
    "\n",
    "# cabin 컬럼을 삭제 \n",
    "X_train = X_train.drop('cabin', axis=1) \n",
    "X_test = X_test.drop('cabin', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embarked 컬럼 (train1, test1 결측) \n",
    "# embarked는 탑승한 곳을 의미하고, 범주형으로 (C, Q, S 中) '최다빈도'를 가지는 범주로 '대체'함 \n",
    "\n",
    "# 최다빈도 \n",
    "# ; value_counts-시리즈 값이 정수, 문자열, 카테고리 값인 경우 각각 값이 나온 횟수 \n",
    "# ; idxmax- 데이터프레임 내 값 중, 최고값의 인덱스 위치 리턴  \n",
    "# ; idxmin- \" \" 최소값의 \" \" \n",
    "\n",
    "top = X_train['embarked'].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대치 \n",
    "# 누락된 데이터(NaN) 채우기 - 괄호 안의 top으로(최다빈도) 채우기 \n",
    "X_train['embarked'] = X_train['embarked'].fillna(top) \n",
    "X_test['embarked'] = X_test['embarked'].fillna(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex           3\n",
      "ticket      621\n",
      "embarked      3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# @ Step3-3. (3)카테고리형 컬럼 전처리 | 카테고리형(숫자형이 아닌 것)\n",
    "# 문자열(object) 컬럼들의 유일값 수 확인 \n",
    "\n",
    "# ; select_dtypes: 특정 데이터(object)만 호출하기 \n",
    "# ; unique: 유일한 값. 고유값 찾기 | 유일값이란?(:데이터에 있는 고유값)\n",
    "# ; nunique: 데이터 고유값들의 수 출력 (중복값 제외하고 산출) (MC 분류수 산출) \n",
    "\n",
    "print(X_train.select_dtypes('object').nunique())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex           3\n",
      "ticket      445\n",
      "embarked      3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_test.select_dtypes('object').nunique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      517\n",
       "female    244\n",
       "F          23\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (카테고리형 컬럼 확인 시) 특이한 것, 문제가 있는 것 처리 \n",
    "\n",
    "# (sex 컬럼) - 여성에 대한 일부 카테고리가 'F'로 되어있음 \n",
    "\n",
    "X_train['sex'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      325\n",
       "female    173\n",
       "F          26\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['sex'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train,test 내 (sex 컬럼)의 'F'를 'female'로 통일 (replace)\n",
    "\n",
    "X_train['sex'] = X_train['sex'].map({'male':'male', 'female':'female', 'F':'female'}) \n",
    "X_test['sex'] = X_test['sex'].map({'male':'male', 'female':'female', 'F':'female'}) \n",
    "\n",
    "# map함수 이용하지 않을 경우는, for반복문 이용해서 일일이 하나하나 리스트에 접근해서 계산해서 하나씩 또 append 해줘야 하는데, \n",
    "# map함수 이용하면, 요소에 적용한 함수 하나만 넘겨주면 알아서 자동적으로 리스트를 함수에 적용해서 map객체를 리턴  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ticket 컬럼) \n",
    "# 대다수가 중복되지 않으므로 컬럼을 삭제하는 것으로 결정 -> 어느 한 MC로 그룹핑이 안되고 특징이 없다는 뜻. \n",
    "\n",
    "X_train = X_train.drop('ticket', axis=1) \n",
    "X_test = X_test.drop('ticket', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-4. (4)수치형 컬럼 전처리 \n",
    "\n",
    "# pclass 컬럼\n",
    "# 수치형으로 인식되지만 1,2,3등석 정보를 각 1,2,3으로 저장한 것으로 \n",
    "# 카테고리의 의미를 가지는 컬럼 (즉, 문자가, 문자가 아닌 숫자 형태로 되어있음)\n",
    "\n",
    "# dtype 변경 후 파생변수 pclass_gp에 할당하고 기존 컬럼 삭제 \n",
    "# ; astype: 열의 요소의 dtype(데이터타입) 변경 \n",
    "\n",
    "X_train['pclass'] = X_train['pclass'].astype('object') \n",
    "X_test['pclass'] = X_test['pclass'].astype('object') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완료 후 삭제 \n",
    "X_train = X_train.drop('pclass', axis=1) \n",
    "X_test = X_test.drop('pclass', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (sibsp, parch 컬럼) | (sib는 형제, sp는 배우자 수) (par는 부모, ch는 자녀 수) \n",
    "# sibsp는 동승한 형제 또는 배우자의 수, parch는 동승한 부모 또는 자녀의 수이므로 \n",
    "# 두 컬럼을 합한 파생변수 fam을 생성하고, 이는 동승한 가족 인원을 의미 \n",
    "\n",
    "X_train['fam'] = X_train['sibsp'] + X_train['parch'] \n",
    "X_test['fam'] = X_test['sibsp'] + X_test['parch'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완료 후 삭제 \n",
    "\n",
    "X_train = X_train.drop(['sibsp','parch'], axis=1) \n",
    "X_test = X_test.drop(['sibsp','parch'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-5. (5)데이터 분할 : 문제에 주어진 train데이터를 train과 valid로 분할하여 X_TRAIN과 X_VAL, y_TRAIN과 y_VAL에 각각 할당한다. (valid: 유효한, 타당한) \n",
    "# train데이터를 train과 valid로 분할(X와 y에서). (@) 따라서 X_test를 이렇게 나눈건 없다(x).\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# X_train과 y_train을 학습용과 검증용으로 분할 \n",
    "# 학습용(X_TRAIN, y_TRAIN), 검증용(X_VAL, y_VAL) \n",
    "\n",
    "X_TRAIN, X_VAL, y_TRAIN, y_VAL = train_test_split(X_train, y_train, random_state=1234, test_size=0.1)\n",
    "\n",
    "# random_state: 세트를 섞을 때 해당 int값 보고 섞음. 하이퍼파라미터 튜닝 시 이 값을 고정해주고 튜닝해야 매번 데이터셋이 변경되는 것 방지 가능.\n",
    "# (random_state은 난수값 고정이고, 어떤 숫자적 의미는 아님)\n",
    "# test_size: 테스트셋 구성의 비율. 0.1은 전체 데이터셋의 10%를 테스트셋으로 지정하겠다는 의미 (default는 0.25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(705, 4)\n"
     ]
    }
   ],
   "source": [
    "# 분할 후 shape 확인 \n",
    "# shape: 넘피 numpy 배열에서, 배열의 형태를 알아보는 함수. 배열의 형태를 튜플로 반환. (행 , 열)\n",
    "\n",
    "print(X_TRAIN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_VAL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(705, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_TRAIN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_VAL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-6. (6)인코딩 \n",
    "# 카테고리형 컬럼에 대해 원-핫 인코딩 수행 \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "# OneHotEncoder: y타겟이 숫자 의미 갖지 않도록 바꿔줌. (데이터의, 거리 정보 없애는데 사용)\n",
    "# (e.g.) 1-> 1001 , 2-> 0100 , 3-> 0010 , 4->0001\n",
    "# OneHotEncoder를 함으로써, 변환된 결과는, numpy.array로. 이를 데이터프레임으로 변환하는 과정이 필요하다.  \n",
    "\n",
    "\n",
    "# 인코딩 할 카테고리형 컬럼만 별도 저장 (사본 저장) \n",
    "X_TRAIN_category = X_TRAIN.select_dtypes('object').copy()\n",
    "X_VAL_category = X_VAL.select_dtypes('object').copy() \n",
    "\n",
    "X_TEST_category = X_test.select_dtypes('object').copy() #소문자\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코딩 \n",
    "\n",
    "enc = OneHotEncoder(sparse=False).fit(X_TRAIN_category)\n",
    "\n",
    "# fit메서드: 훈련하라. 모델을 학습시킬 때 사용. 머신러닝이 데이터에 머신러닝 모델을 맞추는 것(fit) -> fit에서 평균, 표준편차 등 구하고. \n",
    "# sparse(드문,희박한)는, sparse=True가 디폴트. sparse=True면 Matrix 리턴. sparse=False면 array 리턴. \n",
    "\n",
    "# transform: fit을 통해 세운 기준으로 맞춰서 변형하는 함수 \n",
    "\n",
    "X_TRAIN_OH = enc.transform(X_TRAIN_category)\n",
    "X_VAL_OH = enc.transform(X_VAL_category)\n",
    "\n",
    "X_TEST_OH = enc.transform(X_TEST_category) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# □ 데이터 인코딩 : 사이킷런 머신러닝(ML) 알고리즘은, 입력데이터에 문자열 값을 허용하지 않아, 문자열을 숫자형으로 변환하는 과정이 필요 \n",
    "# (encoding ; 정보의 형태나 형식을 변환하는 처리 또는 처리 형식)\n",
    "# 카테고리형인 문자열은 인코딩을 통해 코드값인 숫자형으로 변환할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-7. (7)스케일링 (; 카테고리형이 아닌 숫자 관련된 것)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# StandardScaler: 표준화. 평균이 0이고 분산이 1인 정규분포 만드는 것. Z-score. \n",
    "\n",
    "# 스케일링 할 컬럼만 별도 저장. 사본 저장\n",
    "# select_dtype() 메소드의 exclude 옵션은 해당 dtype을 제외한 모든 dtype을 추출할 때 사용. \n",
    "\n",
    "X_TRAIN_conti=  X_TRAIN.select_dtypes(exclude='object').copy() \n",
    "X_VAL_conti =  X_VAL.select_dtypes(exclude='object').copy() \n",
    "\n",
    "X_TEST_conti =  X_test.select_dtypes(exclude='object').copy()  #소문자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN 데이터 기준으로 스케일링함 \n",
    "\n",
    "scale = StandardScaler().fit(X_TRAIN_conti) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-점수 표준화 \n",
    "\n",
    "X_TRAIN_STD = scale.transform(X_TRAIN_conti) \n",
    "X_VAL_STD = scale.transform(X_VAL_conti) \n",
    "\n",
    "X_TEST_STD = scale.transform(X_TEST_conti) \n",
    "\n",
    "# transform에서 평균,분산,표준편차 등 가지고,  거기에 때리면서 구하면서 표준화. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-8. (8)입력 데이터셋 준비  (*y는 타겟이니까 인코딩/스케일링 안한 것)\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "# 인코딩과 스케일링 된 넘파이 배열 연결  \n",
    "X_TRAIN = np.concatenate([X_TRAIN_OH, X_TRAIN_STD], axis=1)    \n",
    "X_VAL = np.concatenate([X_VAL_OH, X_VAL_STD], axis=1) \n",
    "\n",
    "# concatenate(잇다. 연결하다. 연관시키다) : \n",
    "# concatenate메서드: 선택한 축(axis) 방향으로 배열을 연결하는 메서드 (#axis=1이면 열 방향)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1차원 넘파이 배열로 '평탄화' (*y를)\n",
    "\n",
    "y_TRAIN = y_TRAIN.values.ravel() \n",
    "y_VAL = y_VAL.values.ravel() \n",
    "\n",
    "# (참고) 딕셔너리는 key(키), value(값). \n",
    "# 그 중 키만 뽑을 때 -> key()\n",
    "# 값만 뽑을 때 -> value() \n",
    "# 키,값 쌍으로 뽑고 싶을 때 -> items() \n",
    "\n",
    "# ravel: 1차원 배열로 평평하게 펴주는 함수. (y가 2차원 이상일거라서 1차원으로 펴준 것) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Ⅳ.모델학습) \n",
    "# 모형 후보군: Random Forest , XGBoost , LightGBM \n",
    "\n",
    "# Step4. 모델학습 (\"분류\"알고리즘이니 클래서파이로 임포트)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from xgboost import XGBClassifier \n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step4-1. (1) Random Forest \n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=500, max_depth=3, min_samples_leaf=10, max_features='sqrt', random_state=2022) \n",
    "\n",
    "# 모델학습\n",
    "model_rf = rf.fit(X_TRAIN,y_TRAIN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lhlh0\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "c:\\Users\\lhlh0\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# @ Step4-2. (2) XGBoost \n",
    "\n",
    "xgb = XGBClassifier(max_depth=8, n_estimators=500, nthread=5, min_child_weight=20, gamma=0.5, objective='binary:logistic', use_label_encoder=False, random_state=2022)\n",
    "\n",
    "# 모델학습\n",
    "model_xgb = xgb.fit(X_TRAIN,y_TRAIN,eval_metric='mlogloss')\n",
    "\n",
    "# eval: 평가하다. metric: 미터법. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step4-3. (3) LightGBM \n",
    "\n",
    "lgb = LGBMClassifier(max_depth=8, n_estimators=500, n_jobs=30, min_child_weight=10, learning_rate=0.2, objective='binary', random_state=2022)\n",
    "\n",
    "# 모델학습\n",
    "model_lgb = lgb.fit(X_TRAIN,y_TRAIN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step4-4. 성능평가 (기준: f1-score)를 통한 모델 선정 \n",
    "# 분류 알고리즘 사용, 모형 앙상블 \n",
    "# f1-score: 머신러닝 분류모델 평가 | 분류 성능 0 ~ 1 | 높을수록, 1에 가까울수록 좋은 모델\n",
    "# f1-score는 Precision(정밀도)과 Recall(재현율)의 조화평균(역수의 산술평균의 역수)으로, 주로 분류클래스 간 데이터 불균형이 심각할 때 사용.   \n",
    "\n",
    "from sklearn.metrics import f1_score   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증용 데이터셋을 통한 예측 \n",
    "# 참고로 X_VAL과 y_VAL은, 데이터셋 전처리 단계 중 데이터 분할 스텝에서, 데이터 분할을 학습용과 검증용으로 한 것 (검증용임) \n",
    "\n",
    "pred_rf = model_rf.predict(X_VAL) \n",
    "pred_xgb = model_xgb.predict(X_VAL) \n",
    "pred_lgb = model_lgb.predict(X_VAL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# f1-score 계산 \n",
    "\n",
    "f1_rf = f1_score(y_VAL,pred_rf) \n",
    "print(f1_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "f1_xgb = f1_score(y_VAL, pred_xgb)\n",
    "print(f1_xgb)\n",
    "\n",
    "# 교재는 0.625 정도 나옴 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6792452830188679\n"
     ]
    }
   ],
   "source": [
    "f1_lgb = f1_score(y_VAL, pred_lgb)\n",
    "print(f1_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 단계로, 결과를 제출하기 위한 코드를 작성. \n",
    "# f1-score를 기준으로 Random Forest를 최종 모형으로 선정하고, 평가데이터를 통해 결과를 예측하고, 이를 문제에서 요구하는 형식으로 제출 \n",
    "\n",
    "# Ⅴ.결과제출  @ Step5. 결과 제출하기 \n",
    "# 실제 시험에서 답 제출 시 성능이 가장 우수한 모형 하나만 구현 (배열 연결과 똑같이 하되 Test로)\n",
    "\n",
    "# (e.g.) X1, X2, X3, X4, X5 中, X1을 따로 떼어서 원핫인코딩 수행하고, X2~X5는 표준화 하고 표준편차 구함 \n",
    "# 분리해서 작업했었어서 나중에 concatenate으로 합쳐준 것. 한번에 퉁으로 했으면 합쳐줄 필요없었을텐데\n",
    "\n",
    "X_TEST = np.concatenate([X_TEST_OH, X_TEST_STD], axis=1) \n",
    "\n",
    "y_pred = model_rf.predict(X_TEST) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# □ 데이터 인코딩 : 사이킷런 머신러닝(ML) 알고리즘은, 입력데이터에 문자열 값을 허용하지 않아, 문자열을 숫자형으로 변환하는 과정이 필요 \n",
    "# (encoding ; 정보의 형태나 형식을 변환하는 처리 또는 처리 형식)\n",
    "# 카테고리형인 문자열은 인코딩을 통해 코드값인 숫자형으로 변환할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제에서 요구하는 형태로 변환 필요 \n",
    "\n",
    "obj = {'ID':ID, 'survived':y_pred} \n",
    "\n",
    "# 딕셔너리{key:value} 생성 \n",
    "# series는 1차원 | Data Frame은 2차원 \n",
    "\n",
    "result = pd.DataFrame(obj) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하위에 12345.csv 이름으로 저장하기 \n",
    "\n",
    "result.to_csv(\"12345_csv\", index=False) # 인덱스를 포함하지 않는 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 시험 환경에서 제출하는 최종 제출 코드는 위의 단계에서 필요한 부분만을 선볗하여 제출하면 됨 \n",
    "# 번외로, 실제 시험은 제출하고 끝이지만. 연습 결과 채점 위한 평가 진행 \n",
    "\n",
    "# Ⅵ. 채점 모델 평가  @ Step6. 채점 모델 평가 (번외)\n",
    "# 실제값 \n",
    "\n",
    "actual = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\01회\\titanic3_y_test.csv', encoding='cp949')\n",
    "actual = actual['survived'].ravel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6884422110552764"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 채점 기준이 될 성과지표 값 \n",
    "\n",
    "f1_score(actual, y_pred)\n",
    "\n",
    "# 교재는 0.7083으로 됨 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mo. 2-1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (문제 ①) USArrests 데이터셋을 불러와, UrbanPop이 60 이상인 지역 중 Murder와 Assault의 합 대비 Assault의 비율이 0.05 이상인 레코드 수를 구하여라. \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "exam1 = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\02회\\USArrests.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Murder와 Assault의 합 대비 Assault의 비율에 대한 컬럼 생성 \n",
    "\n",
    "# Murder와 Assault의 합\n",
    "exam1['MA'] = exam1['Murder'] + exam1['Assault'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Murder와 Assault의 합 대비 Assault의 비율\n",
    "\n",
    "exam1['ratio'] = exam1['Assault']/exam1['MA'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UrbanPop이 60 이상이고, ratio가 0.05 이상인 경우 \n",
    "\n",
    "cond = (exam1['UrbanPop']>=60) & (exam1['ratio']>=0.05) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당 \n",
    "\n",
    "result = exam1[cond].shape[0] \n",
    "\n",
    "# 셰입0은 행수(레코드수), 셰입하고 각진 괄호!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력 \n",
    "\n",
    "print(result) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mo. 2-1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (문제 ②) swiss 데이터셋을 불러와, Fertility 컬럼에 대해서 내림차순으로 정렬한 후 정렬한 데이터를 기준으로 홀수번째 레코드들의 평균에서 짝수번째 레코드들의 평균을 뺀 값을 구하여라. \n",
    "# (단, 첫번째 행에 있는 데이터를 1번으로 하고, 결과는 소수점 넷째 자리에서 반올림하여 표현) \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "exam2 = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\02회\\swiss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fertility 컬럼에 대해서 내림차순으로 정렬 \n",
    "\n",
    "sort = exam2['Fertility'].sort_values(ascending=False, ignore_index=True) \n",
    "# ascending=False 내림차순, ignore_index=True 기존 인덱스 무시 \n",
    "# (참고)ascend:올라가다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     92.5\n",
      "1     92.4\n",
      "2     92.2\n",
      "3     87.1\n",
      "4     85.8\n",
      "5     83.8\n",
      "6     83.1\n",
      "7     82.9\n",
      "8     82.4\n",
      "9     80.2\n",
      "10    79.4\n",
      "11    79.3\n",
      "12    77.6\n",
      "13    77.3\n",
      "14    76.9\n",
      "15    76.1\n",
      "16    75.5\n",
      "17    74.2\n",
      "18    72.7\n",
      "19    72.5\n",
      "20    72.0\n",
      "21    71.7\n",
      "22    70.5\n",
      "23    70.4\n",
      "24    69.3\n",
      "25    68.9\n",
      "26    68.3\n",
      "27    67.6\n",
      "28    66.9\n",
      "29    65.7\n",
      "30    65.5\n",
      "31    65.4\n",
      "32    65.1\n",
      "33    65.0\n",
      "34    65.0\n",
      "35    64.4\n",
      "36    64.1\n",
      "37    61.7\n",
      "38    60.5\n",
      "39    58.3\n",
      "40    57.4\n",
      "41    56.6\n",
      "42    55.7\n",
      "43    54.3\n",
      "44    44.7\n",
      "45    42.8\n",
      "46    35.0\n",
      "Name: Fertility, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 홀수번째와 짝수번째 행 번호 생성 \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "idx = np.arange(1,48) \n",
    "# 1이상 48미만 [1,2,3 ... 47]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n"
     ]
    }
   ],
   "source": [
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 홀수 \n",
    "\n",
    "odd = (idx % 2 == 1) \n",
    "# 여기서 %는 나누고 나서 나머지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 짝수 \n",
    "\n",
    "even = (idx % 2 == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차이 \n",
    "\n",
    "diff = sort[odd].mean() - sort[even].mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당 \n",
    "\n",
    "result = round(diff,3) \n",
    "\n",
    "# 반올림. 소수점 3째 셋째 '까지' 반올림. (즉, 넷째 자리에서 반올림) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.453\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력 \n",
    "\n",
    "print(result) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mo. 2-1-3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (문제 ③) CO2 데이터셋을 불러와, Type컬럼이 Mississippi이면서 conc컬럼에서 백의 자리 또는 일의 자리가 5인 경우 레코드들의 수를 구하여라. \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "exam3 =  pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\02회\\CO2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>conc</th>\n",
       "      <th>uptake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quebec</td>\n",
       "      <td>nonchilled</td>\n",
       "      <td>95</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quebec</td>\n",
       "      <td>nonchilled</td>\n",
       "      <td>175</td>\n",
       "      <td>30.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quebec</td>\n",
       "      <td>nonchilled</td>\n",
       "      <td>250</td>\n",
       "      <td>34.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quebec</td>\n",
       "      <td>nonchilled</td>\n",
       "      <td>350</td>\n",
       "      <td>37.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quebec</td>\n",
       "      <td>nonchilled</td>\n",
       "      <td>500</td>\n",
       "      <td>35.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>chilled</td>\n",
       "      <td>250</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>chilled</td>\n",
       "      <td>350</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>chilled</td>\n",
       "      <td>500</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>chilled</td>\n",
       "      <td>675</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>chilled</td>\n",
       "      <td>1000</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Type   Treatment  conc  uptake\n",
       "0        Quebec  nonchilled    95    16.0\n",
       "1        Quebec  nonchilled   175    30.4\n",
       "2        Quebec  nonchilled   250    34.8\n",
       "3        Quebec  nonchilled   350    37.2\n",
       "4        Quebec  nonchilled   500    35.3\n",
       "..          ...         ...   ...     ...\n",
       "79  Mississippi     chilled   250    17.9\n",
       "80  Mississippi     chilled   350    17.9\n",
       "81  Mississippi     chilled   500    17.9\n",
       "82  Mississippi     chilled   675    18.9\n",
       "83  Mississippi     chilled  1000    19.9\n",
       "\n",
       "[84 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quebec          40\n",
       "Mississippi     40\n",
       " Quebec          1\n",
       "quebec           1\n",
       "Mississi/ppi     1\n",
       "Mis/sissippi     1\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam3['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### case 1. Type컬럼이 Mississippi인 경우 \n",
    "# 'Mississi/ppi'와 'Mis/sissippi'이 섞여 있음 \n",
    "# exam3['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '/'를 제거 \n",
    "\n",
    "exam3['Type'] = exam3['Type'].str.replace('/','') \n",
    "\n",
    "# 여기서, str은 문자열 string 의미하고, replace는 교환대체 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mississippi일 조건 \n",
    "\n",
    "case1 = (exam3['Type'] == 'Mississippi') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### case2. conc컬럼에서 백의 자리 또는 일의 자리가 5인 경우 \n",
    "\n",
    "# 백의 자리가 5인 경우 \n",
    "\n",
    "hundred = exam3['conc']//100 == 5 \n",
    "\n",
    "# //는 몫 구하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일의 자리가 5인 경우 \n",
    "\n",
    "one = exam3['conc'].astype('string').str.endswith('5') \n",
    "\n",
    "# 다른 방법. 숫자면, %5 == 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 조건을 만족하는 조건 \n",
    "\n",
    "case2 = hundred | one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당 \n",
    "\n",
    "result = exam3[case1 & case2].shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력 \n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mo. 2-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [작업형 제2유형] \n",
    "# (문제 Ⅱ) 아래는 블랙프라이데이 제품 구매자들의 구매 정보에 관련한 데이터의 일부이다. 주어진 데이터를 이용하여 예측 모형을 만들고 아래에 따라 CSV 파일을 생성하시오. \n",
    "# (문제 조건) (\"회귀 알고리즘 사용\") 성능이 우수한 예측모형을 구축하기 위해서는 적절한 데이터 전처리, Feature Engineering, \"회귀 알고리즘\" 사용, 초매개변수 최적화, 모형 앙상블 등이 수반되어야 한다. \n",
    "# (제출형식) User_ID | Purchase \n",
    "\n",
    "# Ⅰ.데이터셋 불러오기  Ⅱ.데이터셋 확인하기  Ⅲ.데이터셋 전처리  Ⅳ.모델학습  Ⅴ.결과제출  Ⅵ.채점모델평가  \n",
    "# \"Ⅲ.데이터셋 전처리\" - (1)불필요한 컬럼 삭제  (2)결측치 처리  (3)카테고리형 컬럼 전처리  (4)수치형 컬럼 전처리 \n",
    "# (5)데이터 분할  (6)인코딩  (7)스케일링  (8)입력 데이터셋 준비  \n",
    "\n",
    "# MAE (Mean Absolute Error) 평균 절대 오차. 예측 오차 절대값들의 평균 -> \"낮을 수록 좋다\" \n",
    "# MSE (Mean Squared Error) 평균 제곱 오차. 예측 오차 제곱합들의 평균\n",
    "# RMSE (Root Mean Squared Error) 평균 제곱근 오차. MSE의 제곱근 값 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Ⅰ.데이터셋 불러오기) Step1. | 데이터셋 불러오기 \n",
    "\n",
    "import pandas as pd \n",
    "X_train = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\02회\\BlackFriday_X_train.csv') \n",
    "X_test = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\02회\\BlackFriday_X_test.csv')\n",
    "y_train = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\02회\\BlackFriday_y_train.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   User_ID Product_ID Gender    Age  Occupation City_Category  \\\n",
      "0  1001889  P00166642      M  18-25          14             B   \n",
      "1  1003320  P00030842      M  26-35           1             B   \n",
      "2  1003690   P0095742      M  18-25           0             B   \n",
      "3  1002796  P00227642      M  26-35          14             B   \n",
      "4  1001671  P00114542      M  36-45           0             B   \n",
      "\n",
      "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
      "0                          2               0                   8   \n",
      "1                          1               1                   1   \n",
      "2                          2               0                   4   \n",
      "3                          3               0                   1   \n",
      "4                          2               0                   5   \n",
      "\n",
      "   Product_Category_2  Product_Category_3  \n",
      "0                 NaN                 NaN  \n",
      "1                 2.0                15.0  \n",
      "2                 5.0                 NaN  \n",
      "3                 5.0                14.0  \n",
      "4                 NaN                 NaN  \n"
     ]
    }
   ],
   "source": [
    "# (Ⅱ.데이터셋 확인하기) Step2. | 데이터셋 확인하기 \n",
    "\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   User_ID Product_ID Gender    Age  Occupation City_Category  \\\n",
      "0  1004079  P00194042      M  36-45          17             B   \n",
      "1  1000936  P00320942      M  18-25           4             C   \n",
      "2  1000238  P00117242      F  51-55           7             B   \n",
      "3  1005250  P00354142      M  51-55           6             B   \n",
      "4  1005281  P00152742      M  26-35           2             A   \n",
      "\n",
      "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
      "0                          3               1                   8   \n",
      "1                         4+               0                   1   \n",
      "2                          0               0                   8   \n",
      "3                         4+               1                   6   \n",
      "4                          2               0                   5   \n",
      "\n",
      "   Product_Category_2  Product_Category_3  \n",
      "0                11.0                 NaN  \n",
      "1                 4.0                 9.0  \n",
      "2                17.0                 NaN  \n",
      "3                 8.0                 NaN  \n",
      "4                 NaN                 NaN  \n"
     ]
    }
   ],
   "source": [
    "print(X_test.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   User_ID  Purchase\n",
      "0  1001889      7802\n",
      "1  1003320     15412\n",
      "2  1003690      1448\n",
      "3  1002796      3927\n",
      "4  1001671      7091\n"
     ]
    }
   ],
   "source": [
    "print(y_train.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3900 entries, 0 to 3899\n",
      "Data columns (total 11 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   User_ID                     3900 non-null   int64  \n",
      " 1   Product_ID                  3900 non-null   object \n",
      " 2   Gender                      3900 non-null   object \n",
      " 3   Age                         3900 non-null   object \n",
      " 4   Occupation                  3900 non-null   int64  \n",
      " 5   City_Category               3900 non-null   object \n",
      " 6   Stay_In_Current_City_Years  3900 non-null   object \n",
      " 7   Marital_Status              3900 non-null   int64  \n",
      " 8   Product_Category_1          3900 non-null   int64  \n",
      " 9   Product_Category_2          2695 non-null   float64\n",
      " 10  Product_Category_3          1213 non-null   float64\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 335.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Step 2-2. | 데이터셋 요약 정보 확인 ; 오브젝트는 문자형임\n",
    "\n",
    "print(X_train.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2600 entries, 0 to 2599\n",
      "Data columns (total 11 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   User_ID                     2600 non-null   int64  \n",
      " 1   Product_ID                  2600 non-null   object \n",
      " 2   Gender                      2600 non-null   object \n",
      " 3   Age                         2600 non-null   object \n",
      " 4   Occupation                  2600 non-null   int64  \n",
      " 5   City_Category               2600 non-null   object \n",
      " 6   Stay_In_Current_City_Years  2600 non-null   object \n",
      " 7   Marital_Status              2600 non-null   int64  \n",
      " 8   Product_Category_1          2600 non-null   int64  \n",
      " 9   Product_Category_2          1752 non-null   float64\n",
      " 10  Product_Category_3          793 non-null    float64\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 223.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X_test.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3900 entries, 0 to 3899\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   User_ID   3900 non-null   int64\n",
      " 1   Purchase  3900 non-null   int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 61.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(y_train.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            User_ID   Occupation  Marital_Status  Product_Category_1  \\\n",
      "count  3.900000e+03  3900.000000     3900.000000         3900.000000   \n",
      "mean   1.002986e+06     7.980513        0.420000            5.273846   \n",
      "std    1.711858e+03     6.562434        0.493622            3.710045   \n",
      "min    1.000002e+06     0.000000        0.000000            1.000000   \n",
      "25%    1.001501e+06     2.000000        0.000000            1.000000   \n",
      "50%    1.003046e+06     7.000000        0.000000            5.000000   \n",
      "75%    1.004386e+06    14.000000        1.000000            8.000000   \n",
      "max    1.006040e+06    20.000000        1.000000           18.000000   \n",
      "\n",
      "       Product_Category_2  Product_Category_3  \n",
      "count         2695.000000         1213.000000  \n",
      "mean             9.852319           12.663644  \n",
      "std              5.058134            4.057423  \n",
      "min              2.000000            3.000000  \n",
      "25%              5.000000            9.000000  \n",
      "50%              9.000000           14.000000  \n",
      "75%             15.000000           16.000000  \n",
      "max             18.000000           18.000000  \n"
     ]
    }
   ],
   "source": [
    "# Step 2-3. | 기초통계량 확인 \n",
    "\n",
    "print(X_train.describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            User_ID   Occupation  Marital_Status  Product_Category_1  \\\n",
      "count  2.600000e+03  2600.000000     2600.000000         2600.000000   \n",
      "mean   1.002952e+06     8.061154        0.403846            5.359231   \n",
      "std    1.718149e+03     6.525626        0.490762            3.769651   \n",
      "min    1.000001e+06     0.000000        0.000000            1.000000   \n",
      "25%    1.001406e+06     2.000000        0.000000            2.000000   \n",
      "50%    1.003012e+06     7.000000        0.000000            5.000000   \n",
      "75%    1.004385e+06    14.000000        1.000000            8.000000   \n",
      "max    1.006037e+06    20.000000        1.000000           18.000000   \n",
      "\n",
      "       Product_Category_2  Product_Category_3  \n",
      "count         1752.000000          793.000000  \n",
      "mean             9.748288           12.813367  \n",
      "std              5.080618            4.098900  \n",
      "min              2.000000            4.000000  \n",
      "25%              5.000000            9.000000  \n",
      "50%              9.000000           15.000000  \n",
      "75%             15.000000           16.000000  \n",
      "max             18.000000           18.000000  \n"
     ]
    }
   ],
   "source": [
    "print(X_test.describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            User_ID      Purchase\n",
      "count  3.900000e+03   3900.000000\n",
      "mean   1.002986e+06   9394.564615\n",
      "std    1.711858e+03   5039.666976\n",
      "min    1.000002e+06    373.000000\n",
      "25%    1.001501e+06   5841.750000\n",
      "50%    1.003046e+06   8062.500000\n",
      "75%    1.004386e+06  12162.750000\n",
      "max    1.006040e+06  23942.000000\n"
     ]
    }
   ],
   "source": [
    "print(y_train.describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Ⅲ.데이터셋 전처리\" - (1)불필요한 컬럼 삭제  (2)결측치 처리  (3)카테고리형 컬럼 전처리  (4)수치형 컬럼 전처리 \n",
    "# (5)데이터 분할  (6)인코딩  (7)스케일링  (8)입력 데이터셋 준비  \n",
    "\n",
    "# (Ⅲ.데이터셋 전처리) @ Step3. 데이터셋 전처리 \n",
    "\n",
    "# Step3-1. (1)불필요한 컬럼 삭제 : 데이터셋으로부터 User_ID, Product_ID 컬럼을 삭제한다. \n",
    " \n",
    "# User_ID 컬럼은 탑승자에 대한 고유 정보로 key 역할로 모델에는 불필요함 \n",
    "\n",
    "# 결과 제출 시에는 X_test의 ID컬럼이 필요하기 때문에 별도 저장 \n",
    "\n",
    "User_ID = X_test['User_ID'].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product_ID는 제품의 고유 ID로 마찬가지로 삭제함 \n",
    "\n",
    "# 데이터들에서 User_ID, Product_ID 컬럼 삭제 \n",
    "\n",
    "X_train = X_train.drop(columns = ['User_ID' , 'Product_ID']) \n",
    "\n",
    "X_test = X_test.drop(columns = ['User_ID' , 'Product_ID']) \n",
    "\n",
    "y_train = y_train.drop(columns = 'User_ID') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                           0\n",
       "Age                              0\n",
       "Occupation                       0\n",
       "City_Category                    0\n",
       "Stay_In_Current_City_Years       0\n",
       "Marital_Status                   0\n",
       "Product_Category_1               0\n",
       "Product_Category_2            1205\n",
       "Product_Category_3            2687\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3-2. (2)결측치 처리 \n",
    "# : Train, Test 양쪽의 결측치를 확인하고, 결측치의 수 등을 기준으로 열을 삭제함 \n",
    "\n",
    "# 결측치 확인 \n",
    "X_train.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                           0\n",
       "Age                              0\n",
       "Occupation                       0\n",
       "City_Category                    0\n",
       "Stay_In_Current_City_Years       0\n",
       "Marital_Status                   0\n",
       "Product_Category_1               0\n",
       "Product_Category_2             848\n",
       "Product_Category_3            1807\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인 \n",
    "X_test.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product_Category_2 컬럼 (train 1205, test 848 결측) \n",
    "# train은 레코드의 31%, test는 레코드의 33%가 결측이고, Product_Category_1의 하위 카테고리 \n",
    "# 컬럼을 삭제 \n",
    "\n",
    "X_train = X_train.drop('Product_Category_2', axis=1) \n",
    "X_test = X_test.drop('Product_Category_2', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product_Category_3 컬럼 (train 2687, test 1807 결측) \n",
    "# train은 레코드의 69%, test는 레코드의 70%가 결측이고, Product_Category_1,2의 하위 카테고리 \n",
    "# 컬럼을 삭제 \n",
    "\n",
    "X_train = X_train.drop('Product_Category_3', axis=1) \n",
    "X_test = X_test.drop('Product_Category_3', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-3. (3)카테고리형 컬럼 전처리 | 카테고리형(숫자형이 아닌 것)\n",
    "\n",
    "# 문자열(object) 컬럼들의 유일값 수 확인 \n",
    "\n",
    "# ; select_dtypes: 특정 데이터(object)만 호출하기 \n",
    "# ; unique: 유일한 값. 고유값 찾기 | 유일값이란?(:데이터에 있는 고유값)\n",
    "# ; nunique: 데이터 고유값들의 수 출력 (중복값 제외하고 산출) (MC 분류수 산출) \n",
    "\n",
    "# 컬럼별 카테고리 확인 결과 큰 이상 없음 ~~!! (여기서는)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender                        2\n",
      "Age                           7\n",
      "City_Category                 3\n",
      "Stay_In_Current_City_Years    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.select_dtypes('object').nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender                        2\n",
      "Age                           7\n",
      "City_Category                 3\n",
      "Stay_In_Current_City_Years    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_test.select_dtypes('object').nunique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Occupation  Marital_Status  Product_Category_1\n",
      "0             14               0                   8\n",
      "1              1               1                   1\n",
      "2              0               0                   4\n",
      "3             14               0                   1\n",
      "4              0               0                   5\n",
      "...          ...             ...                 ...\n",
      "3895           2               0                   1\n",
      "3896           0               0                  11\n",
      "3897           4               0                   8\n",
      "3898          16               0                   1\n",
      "3899          12               0                  16\n",
      "\n",
      "[3900 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# @ Step3-4. (4)수치형 컬럼 전처리 //////\n",
    "\n",
    "print(X_train.select_dtypes(exclude='object')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Occupation  Marital_Status  Product_Category_1\n",
      "0             17               1                   8\n",
      "1              4               0                   1\n",
      "2              7               0                   8\n",
      "3              6               1                   6\n",
      "4              2               0                   5\n",
      "...          ...             ...                 ...\n",
      "2595           0               0                   5\n",
      "2596          14               0                   1\n",
      "2597           9               0                   8\n",
      "2598           4               1                   6\n",
      "2599          18               1                  11\n",
      "\n",
      "[2600 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_test.select_dtypes(exclude='object')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Occupation,  Marital_Status,  Product_Category_1 컬럼 \n",
    "\n",
    "# 수치형으로 인식되지만, 카테고리의 의미를 가지는 컬럼 (즉, 문자가, 문자가 아닌 숫자 형태로 되어있음)\n",
    "\n",
    "# dtype 변경 후 파생변수 OCC_gp, Matrial_gp, PC_gp에 할당하고 기존 컬럼 삭제 \n",
    "# ; astype: 열의 요소의 dtype(데이터타입) 변경 \n",
    "\n",
    "X_train['OCC_gp'] = X_train['Occupation'].astype('object') \n",
    "X_test['OCC_gp'] = X_test['Occupation'].astype('object') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Matrial_gp'] = X_train['Marital_Status'].astype('object') \n",
    "X_test['Matrial_gp'] = X_test['Marital_Status'].astype('object') \n",
    "\n",
    "X_train['PC_gp'] = X_train['Product_Category_1'].astype('object') \n",
    "X_test['PC_gp'] = X_test['Product_Category_1'].astype('object') \n",
    "\n",
    "# 모의고사1에서는 각각 데이터타입 변경 완료 후 삭제해주는 작업을 매번 했었는데, 2장에서는 한번에 하려고 함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 컬럼 삭제  (한꺼번에 실행)\n",
    "\n",
    "X_train = X_train.drop(['Occupation', 'Marital_Status', 'Product_Category_1'], axis=1) \n",
    "X_test = X_test.drop(['Occupation', 'Marital_Status', 'Product_Category_1'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-5. (5)데이터 분할 : 문제에 주어진 train데이터를 train과 valid로 분할하여 X_TRAIN과 X_VAL, y_TRAIN과 y_VAL에 각각 할당한다. (valid: 유효한, 타당한) \n",
    "# train데이터를 train과 valid로 분할(X와 y에서). (@) 따라서 X_test를 이렇게 나눈건 없다(x).\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# X_train과 y_train을 학습용과 검증용으로 분할 \n",
    "# 학습용(X_TRAIN, y_TRAIN), 검증용(X_VAL, y_VAL) \n",
    "\n",
    "X_TRAIN, X_VAL, y_TRAIN, y_VAL = train_test_split(X_train, y_train, random_state=1234, test_size=0.3) \n",
    "# (모의1에서는 test_size 0.1로 했었음) \n",
    "\n",
    "# random_state: 세트를 섞을 때 해당 int값 보고 섞음. 하이퍼파라미터 튜닝 시 이 값을 고정해주고 튜닝해야 매번 데이터셋이 변경되는 것 방지 가능.\n",
    "# (random_state은 난수값 고정이고, 어떤 숫자적 의미는 아님)\n",
    "# test_size: 테스트셋 구성의 비율. 0.1은 전체 데이터셋의 10%를 테스트셋으로 지정하겠다는 의미 (default는 0.25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2730, 7)\n"
     ]
    }
   ],
   "source": [
    "# 분할 후 shape 확인 \n",
    "# shape: 넘피 numpy 배열에서, 배열의 형태를 알아보는 함수. 배열의 형태를 튜플로 반환. (행 , 열)\n",
    "\n",
    "print(X_TRAIN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1170, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_VAL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2730, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_TRAIN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1170, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_VAL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-6. (6)인코딩 \n",
    "# 카테고리형 컬럼에 대해 원-핫 인코딩 수행 \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "# OneHotEncoder: y타겟이 숫자 의미 갖지 않도록 바꿔줌. (데이터의, 거리 정보 없애는데 사용)\n",
    "# (e.g.) 1-> 1001 , 2-> 0100 , 3-> 0010 , 4->0001\n",
    "# OneHotEncoder를 함으로써, 변환된 결과는, numpy.array로. 이를 데이터프레임으로 변환하는 과정이 필요하다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩 할 카테고리형 컬럼만 별도 저장 (사본 저장) \n",
    "X_TRAIN_category = X_TRAIN.select_dtypes('object').copy()\n",
    "X_VAL_category = X_VAL.select_dtypes('object').copy() \n",
    "\n",
    "X_TEST_category = X_test.select_dtypes('object').copy() #소문자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코딩 \n",
    "\n",
    "enc = OneHotEncoder(sparse=False).fit(X_TRAIN_category)\n",
    "\n",
    "# fit메서드: 훈련하라. 모델을 학습시킬 때 사용. 머신러닝이 데이터에 머신러닝 모델을 맞추는 것(fit) -> fit에서 평균, 표준편차 등 구하고. \n",
    "# sparse(드문,희박한)는, sparse=True가 디폴트. sparse=True면 Matrix 리턴. sparse=False면 array 리턴. \n",
    "\n",
    "# transform: fit을 통해 세운 기준으로 맞춰서 변형하는 함수 \n",
    "\n",
    "X_TRAIN_OH = enc.transform(X_TRAIN_category)\n",
    "X_VAL_OH = enc.transform(X_VAL_category)\n",
    "\n",
    "X_TEST_OH = enc.transform(X_TEST_category) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-7. (7)스케일링 (; 카테고리형이 아닌 숫자 관련된 것)\n",
    "\n",
    "# -> 여기서는, 스케일링 할 컬럼이 없으므로 생략 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-8. (8)입력 데이터셋 준비  (*y는 타겟이니까 인코딩/스케일링 안한 것)\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "# 인코딩과 스케일링 된 넘파이 배열 연결  \n",
    "#(모의1) X_TRAIN = np.concatenate([X_TRAIN_OH, X_TRAIN_STD], axis=1)    \n",
    "#(모의1) X_VAL = np.concatenate([X_VAL_OH, X_VAL_STD], axis=1) \n",
    "\n",
    "# concatenate(잇다. 연결하다. 연관시키다) : \n",
    "# concatenate메서드: 선택한 축(axis) 방향으로 배열을 연결하는 메서드 (#axis=1이면 열 방향)\n",
    "\n",
    "\n",
    "# 인코딩과 스케일링 된 넘파이 배열 연결  (모의2: 스케일링 생략으로, 모의1 보다 간단히 셋)\n",
    "X_TRAIN = X_TRAIN_OH    \n",
    "X_VAL = X_VAL_OH  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1차원 넘파이 배열로 '평탄화' (*y를)\n",
    "\n",
    "y_TRAIN = y_TRAIN.values.ravel() \n",
    "y_VAL = y_VAL.values.ravel() \n",
    "\n",
    "# (참고) 딕셔너리는 key(키), value(값). \n",
    "# 그 중 키만 뽑을 때 -> key()\n",
    "# 값만 뽑을 때 -> value() \n",
    "# 키,값 쌍으로 뽑고 싶을 때 -> items() \n",
    "\n",
    "# ravel: 1차원 배열로 평평하게 펴주는 함수. (y가 2차원 이상일거라서 1차원으로 펴준 것) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Ⅳ.모델학습) \n",
    "# 모형 후보군: Random Forest , XGBoost , LightGBM \n",
    "\n",
    "# Step4. 모델학습 (\"회귀\" 알고리즘 이니까 클래서파이가 아닌, 리그레서로 임포트)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRFRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step4-1. (1) Random Forest \n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=500, max_depth=3, min_samples_leaf=10, max_features=2, random_state=2022) \n",
    "\n",
    "# 모델학습\n",
    "model_rf = rf.fit(X_TRAIN,y_TRAIN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step4-2. (2) XGBoost \n",
    "\n",
    "xgb = XGBRFRegressor(max_depth=8, n_estimators=500, nthread=5, min_child_weight=20, gamma=0.5, objective='reg:squarederror', use_label_encoder=False, random_state=2022)\n",
    "\n",
    "# 모델학습 (모의2)\n",
    "#(모의1) model_xgb = xgb.fit(X_TRAIN,y_TRAIN,eval_metric='mlogloss')\n",
    "\n",
    "model_xgb = xgb.fit(X_TRAIN,y_TRAIN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step4-3. (3) LightGBM \n",
    "\n",
    "lgb = LGBMRegressor(max_depth=8, n_estimators=500, n_jobs=30, min_child_weight=10, learning_rate=0.2, objective='regression', random_state=2022)\n",
    "\n",
    "# 모델학습\n",
    "model_lgb = lgb.fit(X_TRAIN,y_TRAIN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step4-4. 성능평가 (기준: MAE)를 통한 모델 선정 \n",
    "# 회귀 알고리즘 사용, 모형 앙상블 \n",
    "\n",
    "# MAE (Mean Absolute Error) 평균 절대 오차. 예측 오차 절대값들의 평균 -> \"낮을 수록 좋다\"  \n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증용 데이터셋을 통한 예측 \n",
    "# 참고로 X_VAL과 y_VAL은, 데이터셋 전처리 단계 중 데이터 분할 스텝에서, 데이터 분할을 학습용과 검증용으로 한 것 (검증용임) \n",
    "\n",
    "pred_rf = model_rf.predict(X_VAL) \n",
    "pred_xgb = model_xgb.predict(X_VAL) \n",
    "pred_lgb = model_lgb.predict(X_VAL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3890.5911682476026\n"
     ]
    }
   ],
   "source": [
    "# MAE 계산 \n",
    "\n",
    "mae_rf = mean_absolute_error(y_VAL,pred_rf) \n",
    "print(mae_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2536.4782616770167\n"
     ]
    }
   ],
   "source": [
    "mae_xgb = mean_absolute_error(y_VAL, pred_xgb)\n",
    "print(mae_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2523.4959648495173\n"
     ]
    }
   ],
   "source": [
    "mae_lgb = mean_absolute_error(y_VAL, pred_lgb)\n",
    "print(mae_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 단계로, 결과를 제출하기 위한 코드를 작성. \n",
    "# MAE를 기준으로 LightGBM을 최종 모형으로 선정하고, 평가데이터를 통해 결과를 예측하고, 이를 문제에서 요구하는 형식으로 제출 \n",
    "\n",
    "# Ⅴ.결과제출  @ Step5. 결과 제출하기 \n",
    "# 실제 시험에서 답 제출 시 성능이 가장 우수한 모형 하나만 구현 (배열 연결과 똑같이 하되 Test로)\n",
    "\n",
    "# (모의1) \n",
    "# X_TEST = np.concatenate([X_TEST_OH, X_TEST_STD], axis=1) \n",
    "# y_pred = model_rf.predict(X_TEST) \n",
    "\n",
    "#(모의2)\n",
    "X_TEST = X_TEST_OH \n",
    "y_pred = model_lgb.predict(X_TEST)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# □ 데이터 인코딩 : 사이킷런 머신러닝(ML) 알고리즘은, 입력데이터에 문자열 값을 허용하지 않아, 문자열을 숫자형으로 변환하는 과정이 필요 \n",
    "# (encoding ; 정보의 형태나 형식을 변환하는 처리 또는 처리 형식)\n",
    "# 카테고리형인 문자열은 인코딩을 통해 코드값인 숫자형으로 변환할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제에서 요구하는 형태로 변환 필요 \n",
    "\n",
    "obj = {'User_ID':User_ID, 'Purchase':y_pred} \n",
    "\n",
    "# 딕셔너리{key:value} 생성 \n",
    "# series는 1차원 | Data Frame은 2차원 \n",
    "\n",
    "result = pd.DataFrame(obj) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하위에 67890.csv 이름으로 저장하기 \n",
    "\n",
    "result.to_csv(\"67890_csv\", index=False) # 인덱스를 포함하지 않는 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 시험 환경에서 제출하는 최종 제출 코드는 위의 단계에서 필요한 부분만을 선볗하여 제출하면 됨 \n",
    "# 번외로, 실제 시험은 제출하고 끝이지만. 연습 결과 채점 위한 평가 진행 \n",
    "\n",
    "# Ⅵ. 채점 모델 평가  @ Step6. 채점 모델 평가 (번외)\n",
    "# 실제값 \n",
    "\n",
    "actual = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\02회\\BlackFriday_y_test.csv', encoding='cp949')\n",
    "actual = actual['Purchase'].ravel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2556.0031980180756"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 채점 기준이 될 성과지표 값 \n",
    "\n",
    "mean_absolute_error(actual, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mo.3-1-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (문제 ①) Rabbit 데이터셋을 불러와 'Dose 컬럼'의 제 3사분위수와 제2분위수를 구하고 두 값의 차이의 절댓값을 구한 후 소수점을 버린 값을 출력하여라. \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "exam1=pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\03회\\Rabbit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제 3사분위수, 제2분위수 별도 저장 \n",
    "\n",
    "q3 = exam1['Dose'].quantile(.75) \n",
    "q2 = exam1['Dose'].median() \n",
    "\n",
    "# quantile 분위수 , 0.75: 3분위수 , median: 중앙값 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 값의 차이의 절대값 \n",
    "\n",
    "diff = abs(q3 - q2) \n",
    "\n",
    "# abs: 절대값 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당 \n",
    "\n",
    "result = diff.astype('int64') \n",
    "\n",
    "# int64: 정수형 (소수점 버린 값 출력하라 했으므로) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력 \n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mo.3-1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (문제 ②) Boston 데이터셋을 불러와 'medv 컬럼'에 대해서 동일한 폭으로 binning(구간화) 한 후 가장 많은 빈도를 가지는 구간을 산출하고 해당 구간 내 dis컬럼의 중앙값을 구하여라. (폭은 10을 기준으로 하고 소수점은 둘째 자리까지 나타내시오)  \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "exam3=pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\03회\\Boston.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
       "\n",
       "     ptratio   black  lstat  medv  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# medv 컬럼에 대해서 동일한 폭으로 binning  \n",
    "\n",
    "medv_cut = pd.cut(exam3['medv'], bins=[0, 10, 20, 30, 40, 50]) \n",
    "\n",
    "# 구간화 binning / bucketing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      (20, 30]\n",
       "1      (20, 30]\n",
       "2      (30, 40]\n",
       "3      (30, 40]\n",
       "4      (30, 40]\n",
       "         ...   \n",
       "501    (20, 30]\n",
       "502    (20, 30]\n",
       "503    (20, 30]\n",
       "504    (20, 30]\n",
       "505    (10, 20]\n",
       "Name: medv, Length: 506, dtype: category\n",
       "Categories (5, interval[int64, right]): [(0, 10] < (10, 20] < (20, 30] < (30, 40] < (40, 50]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medv_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 많은 빈도를 가지는 구간을 산출 \n",
    "\n",
    "mode = medv_cut.value_counts().idxmax() \n",
    "\n",
    "# ; unique: 유일한 값. 고유값 찾기 | 유일값이란?(:데이터에 있는 고유값)\n",
    "# ; nunique: 데이터 고유값들의 수 출력 (중복값 제외하고 산출) (MC 분류수 산출) \n",
    "\n",
    "# ; value_counts-시리즈 값이 정수, 문자열, 카테고리 값인 경우 각각 값이 나온 횟수. 값 발생 횟수  \n",
    "# ; idxmax- 데이터프레임 내 값 중, 최고값의 인덱스 위치 리턴  \n",
    "# ; idxmin- \" \" 최소값의 \" \" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Interval(20, 30, closed='right')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당구간 내 dis 컬럼의 중앙값 \n",
    "\n",
    "# 조건 \n",
    "cond = (medv_cut == mode) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중앙값 \n",
    "\n",
    "median = exam3['dis'][cond].median()  # 중앙값\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당 \n",
    "# 반올림 소수점 셋째자리에서 (둘째자리까지 남기기)\n",
    "\n",
    "result = round(median, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.95\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력 \n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mo. 3-1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (문제 ③) Melanoma 데이터셋을 불러와 1번째~122번째 레코드와 123번째 이후 레코드로 데이터셋을 분리하고 \n",
    "# 각 데이터셋별로 'thickness 칼럼'을 z-score 정규화로 변환한 후 -1과 1 사이 값들의 중앙값을 각각 산출한 후, '합계'를 구하여라. \n",
    "# (단, z-score 정규화 변환 계산에 사용되는 평균과 표준편차는 분리된 것과 관계 없이 1번째~122번째 레코드로 이루어진 데이터셋을 기준으로 하고, \n",
    "# 출력 시 소수점 넷째자리'까지' 반올림하여 나타낼 것)\n",
    "\n",
    "import pandas as pd\n",
    "exam3=pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\03회\\Melanoma.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번째~122번째 레코드와 123번째 이후 레코드로 데이터셋을 분리 \n",
    "\n",
    "df1 = exam3.loc[:123]  # 123'미만' \n",
    "df2 = exam3.loc[123:] \n",
    "\n",
    "# loc(location) 함수: 데이터프레임의 행 또는 칼럼의 label이나 boolean array로 인덱싱\n",
    "# 즉, 사람이 읽을 수 있는 라벨값으로, 특정값들을 골라오는 방법 \n",
    "# df.loc[행 인덱싱 값, 열 인덱싱 값] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>year</th>\n",
       "      <th>thickness</th>\n",
       "      <th>ulcer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>1972</td>\n",
       "      <td>6.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>1968</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1977</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>1968</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1965</td>\n",
       "      <td>12.08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2150</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1972</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2156</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>1972</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2165</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>1972</td>\n",
       "      <td>5.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2209</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>1971</td>\n",
       "      <td>9.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2227</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>1971</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     time  status  sex  age  year  thickness  ulcer\n",
       "0      10       3    1   76  1972       6.76      1\n",
       "1      30       3    1   56  1968       0.65      0\n",
       "2      35       2    1   41  1977       1.34      0\n",
       "3      99       3    0   71  1968       2.90      0\n",
       "4     185       1    1   52  1965      12.08      1\n",
       "..    ...     ...  ...  ...   ...        ...    ...\n",
       "119  2150       2    0   33  1972       0.65      0\n",
       "120  2156       2    0   45  1972       0.97      0\n",
       "121  2165       2    1   62  1972       5.64      0\n",
       "122  2209       2    0   72  1971       9.66      0\n",
       "123  2227       2    0   51  1971       0.10      0\n",
       "\n",
       "[124 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>year</th>\n",
       "      <th>thickness</th>\n",
       "      <th>ulcer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2227</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>1971</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2227</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>1971</td>\n",
       "      <td>5.48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2256</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1971</td>\n",
       "      <td>2.26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2264</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>1971</td>\n",
       "      <td>4.83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2339</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1971</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>4492</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1965</td>\n",
       "      <td>7.06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>4668</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1965</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>4688</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>4926</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1964</td>\n",
       "      <td>2.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>5565</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1962</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     time  status  sex  age  year  thickness  ulcer\n",
       "123  2227       2    0   51  1971       0.10      0\n",
       "124  2227       2    1   77  1971       5.48      1\n",
       "125  2256       1    0   43  1971       2.26      1\n",
       "126  2264       2    0   65  1971       4.83      1\n",
       "127  2339       2    0   63  1971       0.97      0\n",
       "..    ...     ...  ...  ...   ...        ...    ...\n",
       "200  4492       2    1   29  1965       7.06      1\n",
       "201  4668       2    0   40  1965       6.12      0\n",
       "202  4688       2    0   42  1965       0.48      0\n",
       "203  4926       2    0   50  1964       2.26      0\n",
       "204  5565       2    0   41  1962       2.90      0\n",
       "\n",
       "[82 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'thickness 칼럼'을 z-score 정규화로 변환 \n",
    "\n",
    "# 1번째~122번째 레코드로 이루어진 데이터셋의 thickness 평균 \n",
    "avg = df1['thickness'].mean() \n",
    "\n",
    "# 1번째~122번째 레코드로 이루어진 데이터셋의 thickness 표준편차 \n",
    "sd = df1['thickness'].std() \n",
    "\n",
    "# z-score 변환 #\n",
    "std1 = (df1['thickness'] - avg)/sd \n",
    "std2 = (df2['thickness'] - avg)/sd \n",
    "\n",
    "# (단, z-score 정규화 변환 계산에 사용되는 평균과 표준편차는 분리된 것과 관계 없이 1번째~122번째 레코드로 이루어진 데이터셋을 기준으로 하고, \n",
    "# 출력 시 소수점 넷째자리까지 반올림하여 나타낼 것) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1과 1 사이 값들의 중앙값을 각각 산출 \n",
    "# -1과 1 사이 값 \n",
    "\n",
    "sub_std1 = std1[(std1>=-1) & (std1<=1)] \n",
    "sub_std2 = std2[(std2>=-1) & (std2<=1)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중앙값 \n",
    "\n",
    "med1 = sub_std1.median() \n",
    "med2 = sub_std2.median() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당 \n",
    "\n",
    "result = round(med1 + med2, 4) \n",
    "\n",
    "# 소수점 넷째자리'까지' 반올림 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0088\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력 \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-score 구하기 공식 \n",
    "# z = (x - μ) / σ \n",
    "# x: 데이터 값 , μ: 평균 , σ: 표준편차 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mo. 3-2-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [작업형 제2유형] \n",
    "# (문제 Ⅱ) 아래는 호주의 기상 관측소들의 일자별 기상 정보와 강수 여부에 관련한 데이터의 일부이다. 주어진 데이터를 이용하여 예측 모형을 만들고 아래에 따라 CSV 파일을 생성하시오. \n",
    "# (문제 조건) (\"분류 알고리즘 사용\") 성능이 우수한 예측모형을 구축하기 위해서는 적절한 데이터 전처리, Feature Engineering, \n",
    "# \"분류 알고리즘\" 사용, 초매개변수 최적화, 모형 앙상블 등이 수반되어야 하며, 시계열성을 고려하지 않는다.  \n",
    "# (제출형식) Date(날짜) | RainTomorrow_Prob(강수 여부 예측 확률) \n",
    "\n",
    "# Ⅰ.데이터셋 불러오기  Ⅱ.데이터셋 확인하기  Ⅲ.데이터셋 전처리  Ⅳ.모델학습  Ⅴ.결과제출  Ⅵ.채점모델평가  \n",
    "# \"Ⅲ.데이터셋 전처리\" - (1)불필요한 컬럼 삭제  (2)결측치 처리  (3)카테고리형 컬럼 전처리  (4)수치형 컬럼 전처리 \n",
    "# (5)데이터 분할  (6)인코딩  (7)스케일링  (8)입력 데이터셋 준비  \n",
    "\n",
    "\n",
    "# (Ⅰ.데이터셋 불러오기) Step1. | 데이터셋 불러오기 \n",
    "\n",
    "import pandas as pd \n",
    "X_train = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\03회\\weatherAUS_X_train.csv') \n",
    "X_test = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\03회\\weatherAUS_X_test.csv')\n",
    "y_train = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\03회\\weatherAUS_y_train.csv')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date Location  MinTemp  MaxTemp  Rainfall WindGustDir  WindGustSpeed  \\\n",
      "0  2016-01-01   Albury     20.4     37.6       0.0         ENE           54.0   \n",
      "1  2016-01-02   Albury     20.9     33.6       0.4         SSE           50.0   \n",
      "2  2016-01-03   Albury     18.4     23.1       2.2         ENE           48.0   \n",
      "3  2016-01-04   Albury     17.3     23.7      15.6         SSE           39.0   \n",
      "4  2016-01-05   Albury     15.5     22.9       6.8         ENE           31.0   \n",
      "\n",
      "  WindDir9am WindDir3pm  WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  \\\n",
      "0        NaN        ESE           0.0           7.0         46.0         17.0   \n",
      "1        SSE         SE           9.0          17.0         54.0         30.0   \n",
      "2        ESE        ENE          11.0          39.0         62.0         67.0   \n",
      "3         SE        SSE           9.0          17.0         74.0         65.0   \n",
      "4         SE        SSE           6.0           9.0         92.0         63.0   \n",
      "\n",
      "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm RainToday  \n",
      "0       1013.4       1009.2       7.0       3.0     26.1     36.7        No  \n",
      "1       1011.1       1008.4       8.0       8.0     24.8     31.7        No  \n",
      "2       1014.0       1014.8       8.0       8.0     21.8     19.5       Yes  \n",
      "3       1017.9       1016.5       8.0       8.0     19.2     21.6       Yes  \n",
      "4       1016.3       1013.9       8.0       8.0     17.2     22.2       Yes  \n"
     ]
    }
   ],
   "source": [
    "# (Ⅱ.데이터셋 확인하기) Step2. | 데이터셋 확인하기 \n",
    "\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date Location  MinTemp  MaxTemp  Rainfall WindGustDir  WindGustSpeed  \\\n",
      "0  2016-09-01   Albury      8.5     16.7       0.4         NNE           17.0   \n",
      "1  2016-09-02   Albury      6.1     13.9       0.2         SSE           37.0   \n",
      "2  2016-09-03   Albury      9.6     16.6      33.6         WNW           48.0   \n",
      "3  2016-09-04   Albury      7.7     15.1       0.6          NW           26.0   \n",
      "4  2016-09-05   Albury      4.4     15.9       0.0           W           24.0   \n",
      "\n",
      "  WindDir9am WindDir3pm  WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  \\\n",
      "0        NaN         NW           0.0          11.0         96.0         65.0   \n",
      "1          S          E           6.0           7.0         87.0         76.0   \n",
      "2          W          W          15.0          31.0         90.0         60.0   \n",
      "3        WSW        WNW          20.0          13.0         82.0         66.0   \n",
      "4        ESE        WSW           4.0          13.0         93.0         63.0   \n",
      "\n",
      "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm RainToday  \n",
      "0       1020.0       1016.1       8.0       7.0     12.3     15.8        No  \n",
      "1       1012.1       1005.6       NaN       8.0     10.1     13.5        No  \n",
      "2       1003.4       1008.8       6.0       1.0     11.4     15.1       Yes  \n",
      "3       1023.7       1025.4       8.0       7.0     10.8     14.0        No  \n",
      "4       1031.3       1029.1       8.0       7.0     10.4     14.7        No  \n"
     ]
    }
   ],
   "source": [
    "print(X_test.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date RainTomorrow\n",
      "0  2016-01-01           No\n",
      "1  2016-01-02          Yes\n",
      "2  2016-01-03          Yes\n",
      "3  2016-01-04          Yes\n",
      "4  2016-01-05           No\n"
     ]
    }
   ],
   "source": [
    "print(y_train.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11714 entries, 0 to 11713\n",
      "Data columns (total 20 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Date           11714 non-null  object \n",
      " 1   Location       11714 non-null  object \n",
      " 2   MinTemp        11658 non-null  float64\n",
      " 3   MaxTemp        11662 non-null  float64\n",
      " 4   Rainfall       11630 non-null  float64\n",
      " 5   WindGustDir    11073 non-null  object \n",
      " 6   WindGustSpeed  11073 non-null  float64\n",
      " 7   WindDir9am     10873 non-null  object \n",
      " 8   WindDir3pm     11127 non-null  object \n",
      " 9   WindSpeed9am   11633 non-null  float64\n",
      " 10  WindSpeed3pm   11178 non-null  float64\n",
      " 11  Humidity9am    11650 non-null  float64\n",
      " 12  Humidity3pm    10970 non-null  float64\n",
      " 13  Pressure9am    10503 non-null  float64\n",
      " 14  Pressure3pm    10499 non-null  float64\n",
      " 15  Cloud9am       6937 non-null   float64\n",
      " 16  Cloud3pm       6115 non-null   float64\n",
      " 17  Temp9am        11674 non-null  float64\n",
      " 18  Temp3pm        10987 non-null  float64\n",
      " 19  RainToday      11630 non-null  object \n",
      "dtypes: float64(14), object(6)\n",
      "memory usage: 1.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Step 2-2. | 데이터셋 요약 정보 확인 ; 오브젝트는 문자형임\n",
    "\n",
    "print(X_train.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5794 entries, 0 to 5793\n",
      "Data columns (total 20 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Date           5794 non-null   object \n",
      " 1   Location       5794 non-null   object \n",
      " 2   MinTemp        5774 non-null   float64\n",
      " 3   MaxTemp        5782 non-null   float64\n",
      " 4   Rainfall       5711 non-null   float64\n",
      " 5   WindGustDir    5447 non-null   object \n",
      " 6   WindGustSpeed  5447 non-null   float64\n",
      " 7   WindDir9am     5645 non-null   object \n",
      " 8   WindDir3pm     5534 non-null   object \n",
      " 9   WindSpeed9am   5773 non-null   float64\n",
      " 10  WindSpeed3pm   5546 non-null   float64\n",
      " 11  Humidity9am    5678 non-null   float64\n",
      " 12  Humidity3pm    5345 non-null   float64\n",
      " 13  Pressure9am    5189 non-null   float64\n",
      " 14  Pressure3pm    5188 non-null   float64\n",
      " 15  Cloud9am       3228 non-null   float64\n",
      " 16  Cloud3pm       2719 non-null   float64\n",
      " 17  Temp9am        5777 non-null   float64\n",
      " 18  Temp3pm        5439 non-null   float64\n",
      " 19  RainToday      5711 non-null   object \n",
      "dtypes: float64(14), object(6)\n",
      "memory usage: 905.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X_test.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11714 entries, 0 to 11713\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Date          11714 non-null  object\n",
      " 1   RainTomorrow  11714 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 183.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(y_train.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            MinTemp       MaxTemp      Rainfall  WindGustSpeed  WindSpeed9am  \\\n",
      "count  11658.000000  11662.000000  11630.000000   11073.000000  11633.000000   \n",
      "mean      12.530057     23.049974      2.546174      38.853698     13.453537   \n",
      "std        6.551759      7.531580      9.042366      13.732184      8.696536   \n",
      "min       -7.800000     -4.800000      0.000000       7.000000      0.000000   \n",
      "25%        7.800000     17.200000      0.000000      30.000000      7.000000   \n",
      "50%       12.400000     22.600000      0.000000      37.000000     13.000000   \n",
      "75%       17.400000     28.400000      1.000000      46.000000     19.000000   \n",
      "max       29.200000     45.100000    225.000000     120.000000     74.000000   \n",
      "\n",
      "       WindSpeed3pm   Humidity9am   Humidity3pm   Pressure9am   Pressure3pm  \\\n",
      "count  11178.000000  11650.000000  10970.000000  10503.000000  10499.000000   \n",
      "mean      17.971014     72.096996     53.495351   1017.787594   1015.341823   \n",
      "std        8.468756     18.115875     20.736367      6.923373      6.831690   \n",
      "min        0.000000     10.000000      4.000000    982.200000    977.100000   \n",
      "25%       11.000000     61.000000     39.000000   1013.500000   1010.900000   \n",
      "50%       17.000000     74.000000     54.000000   1018.000000   1015.600000   \n",
      "75%       22.000000     86.000000     67.750000   1022.100000   1019.800000   \n",
      "max       63.000000    100.000000    100.000000   1040.300000   1036.400000   \n",
      "\n",
      "          Cloud9am     Cloud3pm       Temp9am       Temp3pm  \n",
      "count  6937.000000  6115.000000  11674.000000  10987.000000  \n",
      "mean      4.931527     5.018152     16.803135     21.444644  \n",
      "std       2.890257     2.711604      6.762189      7.324353  \n",
      "min       0.000000     0.000000     -7.200000     -5.400000  \n",
      "25%       2.000000     2.000000     11.600000     15.900000  \n",
      "50%       6.000000     6.000000     16.500000     21.000000  \n",
      "75%       8.000000     7.000000     21.700000     26.600000  \n",
      "max       8.000000     8.000000     36.500000     43.500000  \n"
     ]
    }
   ],
   "source": [
    "# Step 2-3. | 기초통계량 확인 \n",
    "\n",
    "print(X_train.describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MinTemp      MaxTemp     Rainfall  WindGustSpeed  WindSpeed9am  \\\n",
      "count  5774.000000  5782.000000  5711.000000    5447.000000   5773.000000   \n",
      "mean     12.397194    23.971688     2.021100      42.980540     15.543218   \n",
      "std       6.057115     6.990447     5.992186      13.479326      8.732675   \n",
      "min      -4.800000     1.100000     0.000000      13.000000      0.000000   \n",
      "25%       7.900000    18.600000     0.000000      33.000000      9.000000   \n",
      "50%      11.700000    23.200000     0.000000      41.000000     15.000000   \n",
      "75%      16.500000    29.100000     0.800000      50.000000     20.000000   \n",
      "max      28.900000    42.900000    85.000000     113.000000     65.000000   \n",
      "\n",
      "       WindSpeed3pm  Humidity9am  Humidity3pm  Pressure9am  Pressure3pm  \\\n",
      "count   5546.000000  5678.000000  5345.000000  5189.000000  5188.000000   \n",
      "mean      20.344933    63.949454    49.681572  1014.564232  1012.157132   \n",
      "std        8.764972    18.315154    20.524905     6.688959     6.537446   \n",
      "min        0.000000     4.000000     3.000000   982.000000   981.900000   \n",
      "25%       13.500000    53.000000    35.000000  1011.000000  1008.100000   \n",
      "50%       19.000000    65.000000    50.000000  1014.600000  1012.000000   \n",
      "75%       26.000000    76.000000    63.000000  1019.000000  1016.600000   \n",
      "max       65.000000   100.000000   100.000000  1033.000000  1030.300000   \n",
      "\n",
      "          Cloud9am     Cloud3pm      Temp9am      Temp3pm  \n",
      "count  3228.000000  2719.000000  5777.000000  5439.000000  \n",
      "mean      4.965923     4.967635    17.954613    21.976429  \n",
      "std       2.875166     2.789602     6.205495     6.713617  \n",
      "min       0.000000     0.000000    -3.600000     0.600000  \n",
      "25%       2.000000     2.000000    13.200000    16.900000  \n",
      "50%       6.000000     6.000000    17.300000    21.400000  \n",
      "75%       8.000000     8.000000    22.100000    26.700000  \n",
      "max       8.000000     8.000000    36.200000    42.000000  \n"
     ]
    }
   ],
   "source": [
    "print(X_test.describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Date RainTomorrow\n",
      "count        11714        11714\n",
      "unique         244            2\n",
      "top     2016-05-02           No\n",
      "freq            49         8882\n"
     ]
    }
   ],
   "source": [
    "print(y_train.describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Ⅲ.데이터셋 전처리) @ Step3. 데이터셋 전처리 \n",
    "\n",
    "# Step3-1. (1)불필요한 컬럼 삭제 : 데이터셋으로부터 Date 컬럼을 삭제한다.  \n",
    "# Date컬럼은 관측일자로 key 역할로 모델에는 불필요함 \n",
    "\n",
    "# 결과 제출 시에는 X_test의 Date컬럼이 필요하기 때문에 별도 저장 \n",
    "\n",
    "Date = X_test['Date'].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터들에서 Date 컬럼 삭제 \n",
    "\n",
    "X_train = X_train.drop(columns = 'Date') \n",
    "\n",
    "X_test = X_test.drop(columns = 'Date') \n",
    "\n",
    "y_train = y_train.drop(columns = 'Date') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location            0\n",
       "MinTemp            56\n",
       "MaxTemp            52\n",
       "Rainfall           84\n",
       "WindGustDir       641\n",
       "WindGustSpeed     641\n",
       "WindDir9am        841\n",
       "WindDir3pm        587\n",
       "WindSpeed9am       81\n",
       "WindSpeed3pm      536\n",
       "Humidity9am        64\n",
       "Humidity3pm       744\n",
       "Pressure9am      1211\n",
       "Pressure3pm      1215\n",
       "Cloud9am         4777\n",
       "Cloud3pm         5599\n",
       "Temp9am            40\n",
       "Temp3pm           727\n",
       "RainToday          84\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3-2. (2)결측치 처리 \n",
    "# : Train, Test 양쪽의 결측치를 확인하고 결측치의 수를 기준으로 열을 삭제하거나 결측치를 대치한다. \n",
    "\n",
    "# 결측치 확인 \n",
    "X_train.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location            0\n",
       "MinTemp            20\n",
       "MaxTemp            12\n",
       "Rainfall           83\n",
       "WindGustDir       347\n",
       "WindGustSpeed     347\n",
       "WindDir9am        149\n",
       "WindDir3pm        260\n",
       "WindSpeed9am       21\n",
       "WindSpeed3pm      248\n",
       "Humidity9am       116\n",
       "Humidity3pm       449\n",
       "Pressure9am       605\n",
       "Pressure3pm       606\n",
       "Cloud9am         2566\n",
       "Cloud3pm         3075\n",
       "Temp9am            17\n",
       "Temp3pm           355\n",
       "RainToday          83\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인 \n",
    "X_test.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train에서 500개가 넘는 결측치가 있는 컬럼은 삭제 \n",
    "# 결측치가 500개가 넘는 조건 \n",
    "\n",
    "cond_na500 = (X_train.isna().sum() >= 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 500개가 넘는 컬럼명 \n",
    "\n",
    "col_na500 = X_train.columns[cond_na500] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WindGustDir', 'WindGustSpeed', 'WindDir9am', 'WindDir3pm',\n",
       "       'WindSpeed3pm', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am',\n",
       "       'Cloud3pm', 'Temp3pm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_na500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 삭제 \n",
    "X_train = X_train.drop(col_na500, axis=1) \n",
    "X_test = X_test.drop(col_na500, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location        True\n",
       "MinTemp         True\n",
       "MaxTemp         True\n",
       "Rainfall        True\n",
       "WindSpeed9am    True\n",
       "Humidity9am     True\n",
       "Temp9am         True\n",
       "RainToday       True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train에서 100개 미만의 결측치가 있는 컬럼은 결측치 대체 \n",
    "# 결측치가 100개 미만인 조건  \n",
    "\n",
    "X_train.isna().sum() < 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형인 MinTemp, MaxTemp, Rainfall, WindSpeed9am, Humidity9am, Temp9am은 평균 대체 \n",
    "# 수치형만 있는 데이터프레임 추출  # 문자형은 제외 \n",
    "\n",
    "X_train_conti = X_train.select_dtypes(exclude='object').copy() \n",
    "X_test_conti = X_test.select_dtypes(exclude='object').copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 대치 \n",
    "\n",
    "X_train_conti = X_train_conti.fillna(X_train_conti.mean()) \n",
    "X_test_conti = X_test_conti.fillna(X_train_conti.mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카테고리형인 RainToday는 최다빈도를 가지는 라벨로 대체 \n",
    "\n",
    "# 카테고리형만 있는 데이터프레임 추출 \n",
    "\n",
    "X_train_category = X_train.select_dtypes('object').copy() \n",
    "X_test_category = X_test.select_dtypes('object').copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최다라벨로 대치 \n",
    "\n",
    "mode = X_train_category.value_counts('RainToday').idxmax() \n",
    "\n",
    "X_train_category = X_train_category.fillna(mode) \n",
    "X_test_category = X_test_category.fillna(mode) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 데이터프레임 다시 합치기 (수치형 작업 + 카테고리형 작업)\n",
    "\n",
    "X_train = pd.concat([X_train_conti, X_train_category], axis=1) \n",
    "X_test = pd.concat([X_test_conti, X_test_category], axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 카테고리형 컬럼 전처리: 별도 과정이 없으므로 생략 \n",
    "## 수치형 컬럼 전처리: 별도 과정이 없으므로 생략 \n",
    "\n",
    "# @ Step3-5. (5)데이터 분할 : 문제에 주어진 train데이터를 train과 valid로 분할하여 X_TRAIN과 X_VAL, y_TRAIN과 y_VAL에 각각 할당한다. (valid: 유효한, 타당한) \n",
    "# train데이터를 train과 valid로 분할(X와 y에서). (@) 따라서 X_test를 이렇게 나눈건 없다(x).\n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "# X_train과 y_train을 학습용과 검증용으로 분할 \n",
    "# 학습용(X_TRAIN, y_TRAIN), 검증용(X_VAL, y_VAL) \n",
    "\n",
    "X_TRAIN, X_VAL, y_TRAIN, y_VAL = train_test_split(X_train, y_train, random_state=1234, test_size=0.3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8199, 8)\n"
     ]
    }
   ],
   "source": [
    "# 분할 후 shape 확인 \n",
    "# shape: 넘피 numpy 배열에서, 배열의 형태를 알아보는 함수. 배열의 형태를 튜플로 반환. (행 , 열)\n",
    "\n",
    "print(X_TRAIN.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3515, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_VAL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8199, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_TRAIN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3515, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_VAL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-6. (6)인코딩 \n",
    "# 카테고리형 컬럼에 대해 원-핫 인코딩 수행 \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "# OneHotEncoder: y타겟이 숫자 의미 갖지 않도록 바꿔줌. (데이터의, 거리 정보 없애는데 사용)\n",
    "# (e.g.) 1-> 1001 , 2-> 0100 , 3-> 0010 , 4->0001\n",
    "# OneHotEncoder를 함으로써, 변환된 결과는, numpy.array로. 이를 데이터프레임으로 변환하는 과정이 필요하다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩 할 카테고리형 컬럼만 별도 저장 (사본 저장) \n",
    "X_TRAIN_category = X_TRAIN.select_dtypes('object').copy()\n",
    "X_VAL_category = X_VAL.select_dtypes('object').copy() \n",
    "\n",
    "X_TEST_category = X_test.select_dtypes('object').copy() #소문자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코딩 \n",
    "\n",
    "enc = OneHotEncoder(sparse=False).fit(X_TRAIN_category)\n",
    "\n",
    "# fit메서드: 훈련하라. 모델을 학습시킬 때 사용. 머신러닝이 데이터에 머신러닝 모델을 맞추는 것(fit) -> fit에서 평균, 표준편차 등 구하고. \n",
    "# sparse(드문,희박한)는, sparse=True가 디폴트. sparse=True면 Matrix 리턴. sparse=False면 array 리턴. \n",
    "\n",
    "# transform: fit을 통해 세운 기준으로 맞춰서 변형하는 함수 \n",
    "\n",
    "X_TRAIN_OH = enc.transform(X_TRAIN_category)\n",
    "X_VAL_OH = enc.transform(X_VAL_category)\n",
    "\n",
    "X_TEST_OH = enc.transform(X_TEST_category) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-7. (7)스케일링 (; 카테고리형이 아닌 숫자 관련된 것)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# StandardScaler: 표준화. 평균이 0이고 분산이 1인 정규분포 만드는 것. Z-score. \n",
    "\n",
    "# 스케일링 할 컬럼만 별도 저장. 사본 저장\n",
    "# select_dtype() 메소드의 exclude 옵션은 해당 dtype을 제외한 모든 dtype을 추출할 때 사용. \n",
    "\n",
    "X_TRAIN_conti=  X_TRAIN.select_dtypes(exclude='object').copy() \n",
    "X_VAL_conti =  X_VAL.select_dtypes(exclude='object').copy() \n",
    "\n",
    "X_TEST_conti =  X_test.select_dtypes(exclude='object').copy()  #소문자 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN 데이터 기준으로 스케일링함 \n",
    "\n",
    "scale = StandardScaler().fit(X_TRAIN_conti) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-점수 표준화 \n",
    "\n",
    "X_TRAIN_STD = scale.transform(X_TRAIN_conti) \n",
    "X_VAL_STD = scale.transform(X_VAL_conti) \n",
    "\n",
    "X_TEST_STD = scale.transform(X_TEST_conti) \n",
    "\n",
    "# transform에서 평균,분산,표준편차 등 가지고,  거기에 때리면서 구하면서 표준화. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-8. (8)입력 데이터셋 준비  (*y는 타겟이니까 인코딩/스케일링 안한 것)\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "# 인코딩과 스케일링 된 넘파이 배열 연결  \n",
    "X_TRAIN = np.concatenate([X_TRAIN_OH, X_TRAIN_STD], axis=1)    \n",
    "X_VAL = np.concatenate([X_VAL_OH, X_VAL_STD], axis=1) \n",
    "\n",
    "# concatenate(잇다. 연결하다. 연관시키다) : \n",
    "# concatenate메서드: 선택한 축(axis) 방향으로 배열을 연결하는 메서드 (#axis=1이면 열 방향)\n",
    "\n",
    "# 참고, 넘파이 np에서는 concatenate | 판다스 pd에서는 concat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Yes'와 'No'를 각각 1과 0에 매핑  # ('Yes'와 'No'는 y_train 內 있던 데이터) \n",
    "\n",
    "y_TRAIN = y_TRAIN['RainTomorrow'].map({'No':0, 'Yes':1})\n",
    "y_VAL = y_VAL['RainTomorrow'].map({'No':0, 'Yes':1}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1차원 넘파이 배열로 '평탄화' (*y를)\n",
    "\n",
    "y_TRAIN = y_TRAIN.values.ravel() \n",
    "y_VAL = y_VAL.values.ravel() \n",
    "\n",
    "# (참고) 딕셔너리는 key(키), value(값). \n",
    "# 그 중 키만 뽑을 때 -> key()\n",
    "# 값만 뽑을 때 -> value() \n",
    "# 키,값 쌍으로 뽑고 싶을 때 -> items() \n",
    "\n",
    "# ravel: 1차원 배열로 평평하게 펴주는 함수. (y가 2차원 이상일거라서 1차원으로 펴준 것) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Ⅳ.모델학습) \n",
    "# 모형 후보군: Random Forest , XGBoost , LightGBM \n",
    "\n",
    "# Step4. 모델학습 (\"분류\"알고리즘이니 클래서파이로 임포트)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from xgboost import XGBClassifier \n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step4-1. (1) Random Forest \n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=500, max_depth=3, min_samples_leaf=10, max_features='sqrt', random_state=2022) \n",
    "\n",
    "# 모델학습\n",
    "model_rf = rf.fit(X_TRAIN,y_TRAIN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lhlh0\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "c:\\Users\\lhlh0\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# @ Step4-2. (2) XGBoost \n",
    "\n",
    "xgb = XGBClassifier(max_depth=8, n_estimators=500, nthread=5, min_child_weight=20, gamma=0.5, objective='binary:logistic', use_label_encoder=False, random_state=2022)\n",
    "\n",
    "# 모델학습\n",
    "model_xgb = xgb.fit(X_TRAIN,y_TRAIN,eval_metric='mlogloss')\n",
    "\n",
    "# eval: 평가하다. metric: 미터법. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step4-3. (3) LightGBM \n",
    "\n",
    "lgb = LGBMClassifier(max_depth=8, n_estimators=500, n_jobs=30, min_child_weight=10, learning_rate=0.2, objective='binary', random_state=2022)\n",
    "\n",
    "# 모델학습\n",
    "model_lgb = lgb.fit(X_TRAIN,y_TRAIN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step4-4. 성능평가 (기준: AUC)를 통한 모델 선정 \n",
    "\n",
    "# 분류 알고리즘 사용, 모형 앙상블 \n",
    "\n",
    "# AUC: Area Under the ROC Curve | 분류 성능 0.5 ~ 1 | 높을수록 1에 가까울수록 좋은 모델 , 0.5에 가까울수록 학습이 제대로 안된 모델.  \n",
    "\n",
    "# ROC커브와 AUC를 사용하면 , 분류문제 에서 여러 임계값 설정에 대한 모델의 성능을 구할 수 있게 된다.\n",
    "# ROC커브 : Receiver Operating Characteristic   \n",
    "\n",
    "from sklearn.metrics import roc_curve, auc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증용 데이터셋을 통한 예측 \n",
    "# 참고로 X_VAL과 y_VAL은, 데이터셋 전처리 단계 중 데이터 분할 스텝에서, 데이터 분할을 학습용과 검증용으로 한 것 (검증용임) \n",
    "\n",
    "score_rf = model_rf.predict_proba(X_VAL)[:,1]\n",
    "score_xgb = model_xgb.predict_proba(X_VAL)[:,1]\n",
    "score_lgb = model_lgb.predict_proba(X_VAL)[:,1]  # 이진 분류 \n",
    "\n",
    "\n",
    "# predict 함수와 predict_proba 함수 \n",
    "# predict는 각각의 모델의 최종적인 예측값을 출력 \n",
    "# 회귀 모델의 경우 0.98733...과 같이 구체적으로 특정 값을 출력하게 되고,\n",
    "# 분류 모델의 경우 0, 1, 2와 같이 가장 확률이 높은 클래스를 출력하게 됨 \n",
    "\n",
    "# 이때 분류 모델이 각 클래스에 대한 확률을 일일히 출력하는 것이 predict_proba  (predict probability, 즉 각 클래스의 확률 예측) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7377311116183519\n"
     ]
    }
   ],
   "source": [
    "# AUC 계산 #\n",
    "\n",
    "# roc_curve 함수의 결과를 / fpr, tpr, thresholds 변수로 받아주는 것 \n",
    "\n",
    "# 임계값(thresholds) ; 애매한 값을 분류할 기준이 필요. 이 기준을 임계값이라 함. \n",
    "\n",
    "# 랜덤 포레스트 \n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_VAL, score_rf) \n",
    "auc_rf = auc(fpr, tpr) \n",
    "print(auc_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7448954359191748\n"
     ]
    }
   ],
   "source": [
    "# XGB \n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_VAL, score_xgb) \n",
    "auc_xgb = auc(fpr, tpr) \n",
    "print(auc_xgb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7596543334673899\n"
     ]
    }
   ],
   "source": [
    "# LGB \n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_VAL, score_lgb) \n",
    "auc_lgb = auc(fpr, tpr) \n",
    "print(auc_lgb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 단계로, 결과를 제출하기 위한 코드를 작성. \n",
    "# AUC를 기준으로 LightGBM을 최종 모형으로 선정하고, 평가데이터를 통해 결과를 예측하고, 이를 문제에서 요구하는 형식으로 제출 \n",
    "\n",
    "# Ⅴ.결과제출  @ Step5. 결과 제출하기 \n",
    "# 실제 시험에서 답 제출 시 성능이 가장 우수한 모형 하나만 구현 (배열 연결과 똑같이 하되 Test로)\n",
    "\n",
    "X_TEST = np.concatenate([X_TEST_OH, X_TEST_STD], axis=1) \n",
    "\n",
    "y_score = model_lgb.predict_proba(X_TEST)[:,1] \n",
    "\n",
    "\n",
    "# 기존에는 y_pred 였는데, 여기에서는 pred_ 대신 score_를 썼으므로 'score' 사용 \n",
    "# 기존 predict 사용과 달리 여기에서는 predict_proba이므로, 끝에 [:,1] 붙여주기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# □ 데이터 인코딩 : 사이킷런 머신러닝(ML) 알고리즘은, 입력데이터에 문자열 값을 허용하지 않아, 문자열을 숫자형으로 변환하는 과정이 필요 \n",
    "# (encoding ; 정보의 형태나 형식을 변환하는 처리 또는 처리 형식)\n",
    "# 카테고리형인 문자열은 인코딩을 통해 코드값인 숫자형으로 변환할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제에서 요구하는 형태로 변환 필요 \n",
    "\n",
    "obj = {'Date':Date, 'RainTomorrow':y_score}  \n",
    "\n",
    "# 기존에는 y_pred 였는데, 여기에서는 pred_ 대신 score_를 썼으므로 'score' 사용 \n",
    "\n",
    "# 딕셔너리{key:value} 생성 \n",
    "# series는 1차원 | Data Frame은 2차원 \n",
    "\n",
    "result = pd.DataFrame(obj) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하위에 1233345.csv 이름으로 저장하기 \n",
    "\n",
    "result.to_csv(\"1233345_csv\", index=False) # 인덱스를 포함하지 않는 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 시험 환경에서 제출하는 최종 제출 코드는 위의 단계에서 필요한 부분만을 선볗하여 제출하면 됨 \n",
    "# 번외로, 실제 시험은 제출하고 끝이지만. 연습 결과 채점 위한 평가 진행 \n",
    "\n",
    "# Ⅵ. 채점 모델 평가  @ Step6. 채점 모델 평가 (번외)\n",
    "# 실제값 \n",
    "\n",
    "actual = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\03회\\weatherAUS_y_test.csv', encoding='cp949')\n",
    "actual = actual['RainTomorrow'].ravel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7066865384099572"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 채점 기준이 될 성과지표 값 \n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(actual, y_score, pos_label='Yes')  # pos_label 기준, 1이나 yes. \n",
    "\n",
    "auc(fpr, tpr) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (제2부) Mo.2-1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (문제 ①) Cars93 데이터셋을 불러와 'Turn_circle 칼럼'에 대하여 아래의 과정을 수행하고 '(다)' 단계의 결과값을 출력하여라. \n",
    "\n",
    "# (가) 제 1사분위수와 제 2사분위수를 구하기 \n",
    "# (나) 두 개의 차이의 절대값을 구하기 \n",
    "# (다) 그 값의 소수점을 버리기 \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "exam1 = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\기출복원\\02회\\mtcars2.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.1</td>\n",
       "      <td>6</td>\n",
       "      <td>225.0</td>\n",
       "      <td>105</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.460</td>\n",
       "      <td>20.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.3</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>245</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.570</td>\n",
       "      <td>15.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24.4</td>\n",
       "      <td>4</td>\n",
       "      <td>146.7</td>\n",
       "      <td>62</td>\n",
       "      <td>3.69</td>\n",
       "      <td>3.190</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>140.8</td>\n",
       "      <td>95</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.150</td>\n",
       "      <td>22.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19.2</td>\n",
       "      <td>6</td>\n",
       "      <td>167.6</td>\n",
       "      <td>123</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.440</td>\n",
       "      <td>18.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17.8</td>\n",
       "      <td>6</td>\n",
       "      <td>167.6</td>\n",
       "      <td>123</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.440</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16.4</td>\n",
       "      <td>8</td>\n",
       "      <td>275.8</td>\n",
       "      <td>180</td>\n",
       "      <td>3.07</td>\n",
       "      <td>4.070</td>\n",
       "      <td>17.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17.3</td>\n",
       "      <td>8</td>\n",
       "      <td>275.8</td>\n",
       "      <td>180</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.730</td>\n",
       "      <td>17.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.2</td>\n",
       "      <td>8</td>\n",
       "      <td>275.8</td>\n",
       "      <td>180</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.780</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205</td>\n",
       "      <td>2.93</td>\n",
       "      <td>5.250</td>\n",
       "      <td>17.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.424</td>\n",
       "      <td>17.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.7</td>\n",
       "      <td>8</td>\n",
       "      <td>440.0</td>\n",
       "      <td>230</td>\n",
       "      <td>3.23</td>\n",
       "      <td>5.345</td>\n",
       "      <td>17.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32.4</td>\n",
       "      <td>4</td>\n",
       "      <td>78.7</td>\n",
       "      <td>66</td>\n",
       "      <td>4.08</td>\n",
       "      <td>2.200</td>\n",
       "      <td>19.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30.4</td>\n",
       "      <td>4</td>\n",
       "      <td>75.7</td>\n",
       "      <td>52</td>\n",
       "      <td>4.93</td>\n",
       "      <td>1.615</td>\n",
       "      <td>18.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>33.9</td>\n",
       "      <td>4</td>\n",
       "      <td>71.1</td>\n",
       "      <td>65</td>\n",
       "      <td>4.22</td>\n",
       "      <td>1.835</td>\n",
       "      <td>19.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.5</td>\n",
       "      <td>4</td>\n",
       "      <td>120.1</td>\n",
       "      <td>97</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.465</td>\n",
       "      <td>20.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15.5</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.520</td>\n",
       "      <td>16.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15.2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.435</td>\n",
       "      <td>17.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13.3</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>245</td>\n",
       "      <td>3.73</td>\n",
       "      <td>3.840</td>\n",
       "      <td>15.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>19.2</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.845</td>\n",
       "      <td>17.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27.3</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>66</td>\n",
       "      <td>4.08</td>\n",
       "      <td>1.935</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "      <td>4.43</td>\n",
       "      <td>2.140</td>\n",
       "      <td>16.70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30.4</td>\n",
       "      <td>4</td>\n",
       "      <td>95.1</td>\n",
       "      <td>113</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.513</td>\n",
       "      <td>16.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15.8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>264</td>\n",
       "      <td>4.22</td>\n",
       "      <td>3.170</td>\n",
       "      <td>14.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>19.7</td>\n",
       "      <td>6</td>\n",
       "      <td>145.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.770</td>\n",
       "      <td>15.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>335</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.570</td>\n",
       "      <td>14.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>21.4</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>109</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.780</td>\n",
       "      <td>18.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  carb\n",
       "0   21.0    6  160.0  110  3.90  2.620  16.46   0   1     4     4\n",
       "1   21.0    6  160.0  110  3.90  2.875  17.02   0   1     4     4\n",
       "2   22.8    4  108.0   93  3.85  2.320  18.61   1   1     4     1\n",
       "3   21.4    6  258.0  110  3.08  3.215  19.44   1   0     3     1\n",
       "4   18.7    8    NaN  175  3.15  3.440  17.02   0   0     3     2\n",
       "5   18.1    6  225.0  105  2.76  3.460  20.22   1   0     3     1\n",
       "6   14.3    8  360.0  245  3.21  3.570  15.84   0   0     3     4\n",
       "7   24.4    4  146.7   62  3.69  3.190  20.00   1   0     4     2\n",
       "8   22.8    4  140.8   95  3.92  3.150  22.90   1   0     4     2\n",
       "9   19.2    6  167.6  123  3.92  3.440  18.30   1   0     4     4\n",
       "10  17.8    6  167.6  123  3.92  3.440  18.90   1   0     4     4\n",
       "11  16.4    8  275.8  180  3.07  4.070  17.40   0   0     3     3\n",
       "12  17.3    8  275.8  180  3.07  3.730  17.60   0   0     3     3\n",
       "13  15.2    8  275.8  180  3.07  3.780  18.00   0   0     3     3\n",
       "14  10.4    8    NaN  205  2.93  5.250  17.98   0   0     3     4\n",
       "15  10.4    8    NaN  215  3.00  5.424  17.82   0   0     3     4\n",
       "16  14.7    8  440.0  230  3.23  5.345  17.42   0   0     3     4\n",
       "17  32.4    4   78.7   66  4.08  2.200  19.47   1   1     4     1\n",
       "18  30.4    4   75.7   52  4.93  1.615  18.52   1   1     4     2\n",
       "19  33.9    4   71.1   65  4.22  1.835  19.90   1   1     4     1\n",
       "20  21.5    4  120.1   97  3.70  2.465  20.01   1   0     3     1\n",
       "21  15.5    8  318.0  150  2.76  3.520  16.87   0   0     3     2\n",
       "22  15.2    8    NaN  150  3.15  3.435  17.30   0   0     3     2\n",
       "23  13.3    8  350.0  245  3.73  3.840  15.41   0   0     3     4\n",
       "24  19.2    8  400.0  175  3.08  3.845  17.05   0   0     3     2\n",
       "25  27.3    4   79.0   66  4.08  1.935  18.90   1   1     4     1\n",
       "26  26.0    4    NaN   91  4.43  2.140  16.70   0   1     5     2\n",
       "27  30.4    4   95.1  113  3.77  1.513  16.90   1   1     5     2\n",
       "28  15.8    8    NaN  264  4.22  3.170  14.50   0   1     5     4\n",
       "29  19.7    6  145.0  175  3.62  2.770  15.50   0   1     5     6\n",
       "30  15.0    8    NaN  335  3.54  3.570  14.60   0   1     5     8\n",
       "31  21.4    4  121.0  109  4.11  2.780  18.60   1   1     4     2"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpg와 drat "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9bf15b9dd490fd4628809ac77023ed1d989990ba58b472ec013d0bafd3a285da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
