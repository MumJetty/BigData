{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mo.1-1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (문제 ①) iris 데이터셋을 불러와, Sepal.Width 컬럼에 대해 Sepal.Width의 평균값을 기준으로 3배 표준편차 이상으로 떨어진 값들의 합을 구하여라. \n",
    "\n",
    "import pandas as pd\n",
    "exam1=pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\01회\\iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sepal_width 별도 저장 \n",
    "sepal_width=exam1['Sepal.Width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> sepal_width 평균 기준 3배 표준편차 이상 떨어진 데이터 추출 \n",
    "# sepal_width의 평균 | sepal_width의 표준편차 \n",
    "avg=sepal_width.mean()\n",
    "sd=sepal_width.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상한과 하한 (3배 표준편차 기준)\n",
    "upp=avg+3*sd\n",
    "low=avg-3*sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> sepal_width 평균 기준 3배 표준편차 이상 벗어날 조건\n",
    "# 하한 보다 작고 상한 보다 큼 \n",
    "cond=(sepal_width<low)|(sepal_width>upp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당 \n",
    "# 떨어진 값들의 합 \n",
    "result=sepal_width[cond].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력 \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Series name: Sepal.Width\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "150 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 1.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 요약 정보 확인 \n",
    "print(sepal_width.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    150.000000\n",
      "mean       3.057333\n",
      "std        0.435866\n",
      "min        2.000000\n",
      "25%        2.800000\n",
      "50%        3.000000\n",
      "75%        3.300000\n",
      "max        4.400000\n",
      "Name: Sepal.Width, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 기초통계량 확인 \n",
    "print(sepal_width.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Sepal.Length  150 non-null    float64\n",
      " 1   Sepal.Width   150 non-null    float64\n",
      " 2   Petal.Length  150 non-null    float64\n",
      " 3   Petal.Width   150 non-null    float64\n",
      " 4   Species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 요약 정보 확인 \n",
    "print(exam1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.057333      3.758000     1.199333\n",
      "std        0.828066     0.435866      1.765298     0.762238\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n"
     ]
    }
   ],
   "source": [
    "# 기초통계량 확인 \n",
    "print(exam1.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mo. 1-1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (문제 ②) mtcars1 데이터셋을 불러와, disp 컬럼에 대해서 순위를 부여한 후, 1위부터 20위까지의 값들의 표준편차를 구하고 소수점 셋째자리에서 반올림하여 나타내어라. (단, 동점은 동일한 순위를 부여하되 상위 등수를 기준으로 하며 최댓값을 1위로 함) \n",
    "\n",
    "import pandas as pd\n",
    "exam2=pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\01회\\mtcars1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disp 컬럼 별도 저장 \n",
    "disp=exam2['disp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32 entries, 0 to 31\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   mpg     32 non-null     float64\n",
      " 1   cyl     32 non-null     int64  \n",
      " 2   disp    32 non-null     float64\n",
      " 3   hp      32 non-null     int64  \n",
      " 4   drat    32 non-null     float64\n",
      " 5   wt      32 non-null     float64\n",
      " 6   qsec    32 non-null     float64\n",
      " 7   vs      32 non-null     int64  \n",
      " 8   am      32 non-null     int64  \n",
      " 9   gear    32 non-null     int64  \n",
      " 10  carb    32 non-null     int64  \n",
      "dtypes: float64(5), int64(6)\n",
      "memory usage: 2.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 요약 정보 확인 \n",
    "print(exam2.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             mpg        cyl        disp          hp       drat         wt  \\\n",
      "count  32.000000  32.000000   32.000000   32.000000  32.000000  32.000000   \n",
      "mean   20.090625   6.187500  230.721875  146.687500   3.596563   3.217250   \n",
      "std     6.026948   1.785922  123.938694   68.562868   0.534679   0.978457   \n",
      "min    10.400000   4.000000   71.100000   52.000000   2.760000   1.513000   \n",
      "25%    15.425000   4.000000  120.825000   96.500000   3.080000   2.581250   \n",
      "50%    19.200000   6.000000  196.300000  123.000000   3.695000   3.325000   \n",
      "75%    22.800000   8.000000  326.000000  180.000000   3.920000   3.610000   \n",
      "max    33.900000   8.000000  472.000000  335.000000   4.930000   5.424000   \n",
      "\n",
      "            qsec         vs         am       gear     carb  \n",
      "count  32.000000  32.000000  32.000000  32.000000  32.0000  \n",
      "mean   17.848750   0.437500   0.406250   3.687500   2.8125  \n",
      "std     1.786943   0.504016   0.498991   0.737804   1.6152  \n",
      "min    14.500000   0.000000   0.000000   3.000000   1.0000  \n",
      "25%    16.892500   0.000000   0.000000   3.000000   2.0000  \n",
      "50%    17.710000   0.000000   0.000000   4.000000   2.0000  \n",
      "75%    18.900000   1.000000   1.000000   4.000000   4.0000  \n",
      "max    22.900000   1.000000   1.000000   5.000000   8.0000  \n"
     ]
    }
   ],
   "source": [
    "# 기초통계량 확인 \n",
    "print(exam2.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disp 순위 부여\n",
    "rank=disp.rank(method='min', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1위부터 20위까지 값\n",
    "rank20=disp[rank<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당 \n",
    "# 반올림 소수점 셋째자리에서(둘째자리까지 남기고), 표준편차 구하기 \n",
    "result=round(rank20.std(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.47\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력 \n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mo. 1-1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (문제 ③) Cars93 데이터셋을 불러와, '전체 레코드 수', '결측치가 있는 컬럼의 수', '전체 결측치 수', '결측치가 10개 이상인 컬럼들의 결측치가 있는 레코드만 삭제한 후의 전체 레코드 수'와 '두 개 이상의 컬럼이 동시에 결측인 레코드의 행번호들의 합'을 구한 후 모두 합하여라.  \n",
    "\n",
    "import pandas as pd\n",
    "exam3=pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\01회\\Cars93.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93 entries, 0 to 92\n",
      "Data columns (total 28 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Manufacturer        93 non-null     object \n",
      " 1   Model               93 non-null     object \n",
      " 2   Type                93 non-null     object \n",
      " 3   Min_Price           93 non-null     float64\n",
      " 4   Price               84 non-null     float64\n",
      " 5   Max_Price           93 non-null     float64\n",
      " 6   MPG_city            93 non-null     int64  \n",
      " 7   MPG_highway         93 non-null     int64  \n",
      " 8   AirBags             93 non-null     object \n",
      " 9   DriveTrain          93 non-null     object \n",
      " 10  Cylinders           93 non-null     object \n",
      " 11  EngineSize          93 non-null     float64\n",
      " 12  Horsepower          93 non-null     int64  \n",
      " 13  RPM                 89 non-null     float64\n",
      " 14  Rev_per_mile        93 non-null     int64  \n",
      " 15  Man_trans_avail     93 non-null     object \n",
      " 16  Fuel_tank_capacity  93 non-null     float64\n",
      " 17  Passengers          93 non-null     int64  \n",
      " 18  Length              93 non-null     int64  \n",
      " 19  Wheelbase           93 non-null     int64  \n",
      " 20  Width               93 non-null     int64  \n",
      " 21  Turn_circle         80 non-null     float64\n",
      " 22  Rear_seat_room      91 non-null     float64\n",
      " 23  Luggage_room        82 non-null     float64\n",
      " 24  Weight              93 non-null     int64  \n",
      " 25  Origin              93 non-null     object \n",
      " 26  Unnamed: 26         93 non-null     int64  \n",
      " 27  Make                93 non-null     object \n",
      "dtypes: float64(9), int64(10), object(9)\n",
      "memory usage: 20.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 요약 정보 확인 \n",
    "print(exam3.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Min_Price      Price  Max_Price   MPG_city  MPG_highway  EngineSize  \\\n",
      "count  93.000000  84.000000  93.000000  93.000000    93.000000   93.000000   \n",
      "mean   17.125806  19.047619  21.898925  22.365591    29.086022    2.667742   \n",
      "std     8.746029   9.696608  11.030457   5.619812     5.331726    1.037363   \n",
      "min     6.700000   7.400000   7.900000  15.000000    20.000000    1.000000   \n",
      "25%    10.800000  12.025000  14.700000  18.000000    26.000000    1.800000   \n",
      "50%    14.700000  16.550000  19.600000  21.000000    28.000000    2.400000   \n",
      "75%    20.300000  21.800000  25.300000  25.000000    31.000000    3.300000   \n",
      "max    45.400000  61.900000  80.000000  46.000000    50.000000    5.700000   \n",
      "\n",
      "       Horsepower          RPM  Rev_per_mile  Fuel_tank_capacity  Passengers  \\\n",
      "count   93.000000    89.000000     93.000000           93.000000   93.000000   \n",
      "mean   143.827957  5277.528090   2341.408602           16.664516    5.086022   \n",
      "std     52.374410   602.928989    598.459676            3.279370    1.038979   \n",
      "min     55.000000  3800.000000    825.000000            9.200000    2.000000   \n",
      "25%    103.000000  4800.000000   1980.000000           14.500000    4.000000   \n",
      "50%    140.000000  5200.000000   2340.000000           16.400000    5.000000   \n",
      "75%    170.000000  5750.000000   2595.000000           18.800000    6.000000   \n",
      "max    300.000000  6500.000000   4305.000000           27.000000    8.000000   \n",
      "\n",
      "           Length   Wheelbase      Width  Turn_circle  Rear_seat_room  \\\n",
      "count   93.000000   93.000000  93.000000     80.00000       91.000000   \n",
      "mean   183.204301  103.989247  69.376344     39.10000       27.829670   \n",
      "std     14.602382    7.389026   3.778986      3.29787        2.989072   \n",
      "min    141.000000   85.000000  60.000000     32.00000       19.000000   \n",
      "25%    174.000000   98.000000  67.000000     37.00000       26.000000   \n",
      "50%    183.000000  103.000000  69.000000     39.00000       27.500000   \n",
      "75%    192.000000  110.000000  72.000000     42.00000       30.000000   \n",
      "max    219.000000  124.000000  78.000000     45.00000       36.000000   \n",
      "\n",
      "       Luggage_room       Weight  Unnamed: 26  \n",
      "count     82.000000    93.000000    93.000000  \n",
      "mean      13.890244  3081.505376    46.000000  \n",
      "std        2.997967   704.756104    26.990739  \n",
      "min        6.000000   713.000000     0.000000  \n",
      "25%       12.000000  2620.000000    23.000000  \n",
      "50%       14.000000  3040.000000    46.000000  \n",
      "75%       15.000000  3560.000000    69.000000  \n",
      "max       22.000000  6022.000000    92.000000  \n"
     ]
    }
   ],
   "source": [
    "# 기초통계량 확인 \n",
    "print(exam3.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case1. | 전체 레코드 수 \n",
    "case1=exam3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "# 행 수(셰입0) | 열 수(셰입1) \n",
    "print(exam3.shape[0])\n",
    "print(exam3.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### case2. | -> 결측치가 있는 컬럼의 수 \n",
    "# ; 결측치 조회 및 합 했을 때(이즈앤애이&썸), 0이 아닌 것의 합(썸)\n",
    "case2=sum(exam3.isna().sum() !=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case3. | 전체 결측치 수 , 썸의썸 \n",
    "case3=sum(exam3.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case4. 결측치가 10개 이상인 컬럼들의, 결측치가 있는 레코드만 삭제한 후의, 전체 레코드 수\n",
    "# 결측치 수가 10개 이상인 컬럼명을 colnm_10over에 할당 | ; 쩜 컬럼이 있음  \n",
    "colnm_10over=exam3.columns[exam3.isna().sum()>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#그 중에서 결측치가 없는 경우의 전체 레코드 수 \n",
    "# ; 카피는 사본 생성 | 결측치 row 삭제 후 행수 세기 \n",
    "# ; sub1 안에가 컬럼10오버고, 컬럼10오버 안에가 컬럼확인한 것이므로, len으로 레코드수 확인 가능 \n",
    "sub1=exam3[colnm_10over].copy()\n",
    "case4=len(sub1.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### case5. | 두개 이상의 컬럼이 동시에 결측인 레코드의 행 번호들의 합 \n",
    "# -> 결측치의 수가 2개 이상인 행 인덱스를 rownm_2over에 할당 \n",
    "# (; 인덱스는 리스트 중 특정 원소 몇번째 | axis=1은 컬럼 drop 시 | 결측 컬럼이 2개 이상인 행을 지정하는 것 )\n",
    "rownm_2over=exam3.index[exam3.isna().sum(axis=1) >=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행 번호를 리스트로 반환한 수 합함 \n",
    "sub2=list(rownm_2over)\n",
    "case5=sum(sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "407"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 15, 18, 39, 55, 56, 65, 69, 83]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당 \n",
    "result=case1+case2+case3+case4+case5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력 \n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mo. 1-2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [작업형 제2유형] \n",
    "\n",
    "# (문제 Ⅱ) 아래는 타이타닉호의 탑승자들의 생존과 관련한 데이터이다. 주어진 데이터를 이용하여 예측 모형을 만들고 아래에 따라 CSV 파일을 생성하시오. \n",
    "# (문제 조건) (\"분류 알고리즘 사용\") 성능이 우수한 예측모형을 구축하기 위해서는 적절한 데이터 전처리, Feature Engineering, \"분류 알고리즘\" 사용, 초매개변수 최적화, 모형 앙상블 등이 수반되어야 한다. \n",
    "# (제출형식) ID | survived \n",
    "\n",
    "# Ⅰ.데이터셋 불러오기  Ⅱ.데이터셋 확인하기  Ⅲ.데이터셋 전처리  Ⅳ.모델학습  Ⅴ.결과제출  Ⅵ.채점모델평가  \n",
    "# \"Ⅲ.데이터셋 전처리\" - (1)불필요한 컬럼 삭제  (2)결측치 처리  (3)카테고리형 컬럼 전처리  (4)수치형 컬럼 전처리 \n",
    "# (5)데이터 분할  (6)인코딩  (7)스케일링  (8)입력 데이터셋 준비  \n",
    "\n",
    "# \" 타이타닉 \" \n",
    "# (Ⅰ.데이터셋 불러오기) Step1. | 데이터셋 불러오기 \n",
    "\n",
    "import pandas as pd \n",
    "X_train = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\01회\\titanic3_X_train.csv') \n",
    "X_test = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\01회\\titanic3_X_test.csv')\n",
    "y_train = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\01회\\titanic3_y_train.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  pclass      name   sex   age  sibsp  parch             ticket    fare  \\\n",
      "0   1       3  Sdy*****  male   NaN      0      0             349222  7.8958   \n",
      "1   2       3  Pel*****  male  25.0      0      0  STON/O 2. 3101291  7.9250   \n",
      "2   3       3  Kar*****  male  22.0      0      0             350060  7.5208   \n",
      "3   4       3  Saa*****  male   NaN      0      0               2676  7.2250   \n",
      "4   5       3  Cor*****  male  19.0      0      0             349231  7.8958   \n",
      "\n",
      "  cabin embarked  \n",
      "0   NaN        S  \n",
      "1   NaN        S  \n",
      "2   NaN        S  \n",
      "3   NaN        C  \n",
      "4   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# (Ⅱ.데이터셋 확인하기) Step2. | 데이터셋 확인하기 \n",
    "\n",
    "print(X_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID  pclass      name     sex   age  sibsp  parch    ticket      fare  \\\n",
      "0  786       1  All*****  female   2.0      1      2    113781  151.5500   \n",
      "1  787       1  And*****    male  39.0      0      0    112050    0.0000   \n",
      "2  788       1  Bau*****    male   NaN      0      0  PC 17318   25.9250   \n",
      "3  789       1  Bax*****    male  24.0      0      1  PC 17558  247.5208   \n",
      "4  790       1  Bea*****    male  36.0      0      0     13050   75.2417   \n",
      "\n",
      "     cabin embarked  \n",
      "0  C22 C26        S  \n",
      "1      A36        S  \n",
      "2      NaN        S  \n",
      "3  B58 B60        C  \n",
      "4       C6        C  \n"
     ]
    }
   ],
   "source": [
    "print(X_test.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  survived\n",
      "0   1         0\n",
      "1   2         0\n",
      "2   3         0\n",
      "3   4         0\n",
      "4   5         0\n"
     ]
    }
   ],
   "source": [
    "print(y_train.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785 entries, 0 to 784\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   ID        785 non-null    int64  \n",
      " 1   pclass    785 non-null    int64  \n",
      " 2   name      785 non-null    object \n",
      " 3   sex       785 non-null    object \n",
      " 4   age       628 non-null    float64\n",
      " 5   sibsp     785 non-null    int64  \n",
      " 6   parch     785 non-null    int64  \n",
      " 7   ticket    785 non-null    object \n",
      " 8   fare      784 non-null    float64\n",
      " 9   cabin     171 non-null    object \n",
      " 10  embarked  784 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 67.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Step 2-2. | 데이터셋 요약 정보 확인 ; 오브젝트는 문자형임\n",
    "\n",
    "print(X_train.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 524 entries, 0 to 523\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   ID        524 non-null    int64  \n",
      " 1   pclass    524 non-null    int64  \n",
      " 2   name      524 non-null    object \n",
      " 3   sex       524 non-null    object \n",
      " 4   age       418 non-null    float64\n",
      " 5   sibsp     524 non-null    int64  \n",
      " 6   parch     524 non-null    int64  \n",
      " 7   ticket    524 non-null    object \n",
      " 8   fare      524 non-null    float64\n",
      " 9   cabin     124 non-null    object \n",
      " 10  embarked  523 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 45.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X_test.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785 entries, 0 to 784\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   ID        785 non-null    int64\n",
      " 1   survived  785 non-null    int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 12.4 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(y_train.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ID      pclass         age       sibsp       parch        fare\n",
      "count  785.000000  785.000000  628.000000  785.000000  785.000000  784.000000\n",
      "mean   393.000000    2.296815   30.292994    0.501911    0.357962   33.454697\n",
      "std    226.754272    0.835929   14.660563    1.051146    0.781166   52.251342\n",
      "min      1.000000    1.000000    0.330000    0.000000    0.000000    0.000000\n",
      "25%    197.000000    2.000000   21.000000    0.000000    0.000000    7.895800\n",
      "50%    393.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%    589.000000    3.000000   39.250000    1.000000    0.000000   30.771850\n",
      "max    785.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "# Step 2-3. | 기초통계량 확인 \n",
    "\n",
    "print(X_train.describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ID      pclass         age       sibsp       parch       fare\n",
      "count   524.000000  524.000000  418.000000  524.000000  524.000000  524.00000\n",
      "mean   1047.500000    2.291985   29.262368    0.494275    0.425573   33.05726\n",
      "std     151.410039    0.841475   14.028790    1.028265    0.977859   51.06143\n",
      "min     786.000000    1.000000    0.170000    0.000000    0.000000    0.00000\n",
      "25%     916.750000    1.750000   21.000000    0.000000    0.000000    7.91770\n",
      "50%    1047.500000    3.000000   28.000000    0.000000    0.000000   14.45830\n",
      "75%    1178.250000    3.000000   37.750000    1.000000    0.000000   31.38750\n",
      "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.32920\n"
     ]
    }
   ],
   "source": [
    "print(X_test.describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ID    survived\n",
      "count  785.000000  785.000000\n",
      "mean   393.000000    0.382166\n",
      "std    226.754272    0.486227\n",
      "min      1.000000    0.000000\n",
      "25%    197.000000    0.000000\n",
      "50%    393.000000    0.000000\n",
      "75%    589.000000    1.000000\n",
      "max    785.000000    1.000000\n"
     ]
    }
   ],
   "source": [
    "print(y_train.describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Ⅲ.데이터셋 전처리) @ Step3. 데이터셋 전처리 \n",
    "\n",
    "# Step3-1. (1)불필요한 컬럼 삭제 : 데이터셋으로부터 ID, name 컬럼을 삭제한다.  \n",
    "# ID컬럼은 탑승자에 대한 고유 정보로 key 역할로 모델에는 불필요함 \n",
    "\n",
    "# 결과 제출 시에는 X_test의 ID컬럼이 필요하기 때문에 별도 저장 \n",
    "ID = X_test['ID'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name은 텍스트 전처리 등의 방법으로 분석 가능하기도 하지만 편의상 제외 \n",
    "\n",
    "# 데이터들에서 ID, name 컬럼 삭제 \n",
    "\n",
    "X_train = X_train.drop(columns = ['ID' , 'name']) \n",
    "\n",
    "X_test = X_test.drop(columns = ['ID' , 'name']) \n",
    "\n",
    "y_train = y_train.drop(columns = 'ID') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass        0\n",
       "sex           0\n",
       "age         157\n",
       "sibsp         0\n",
       "parch         0\n",
       "ticket        0\n",
       "fare          1\n",
       "cabin       614\n",
       "embarked      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3-2. (2)결측치 처리 \n",
    "# : Train, Test 양쪽의 결측치를 확인하고 결측치의 수, survived와의 상관관계 등을 기준으로 열 또는 행을 삭제하고 cabin 컬럼은 최다빈도를 가지는 레이블 값으로 대치한다. \n",
    "\n",
    "# 결측치 확인 \n",
    "X_train.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass        0\n",
       "sex           0\n",
       "age         106\n",
       "sibsp         0\n",
       "parch         0\n",
       "ticket        0\n",
       "fare          0\n",
       "cabin       400\n",
       "embarked      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인 \n",
    "X_test.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>524 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass    sex    age  sibsp  parch  ticket   fare  cabin  embarked\n",
       "0     False  False  False  False  False   False  False  False     False\n",
       "1     False  False  False  False  False   False  False  False     False\n",
       "2     False  False   True  False  False   False  False   True     False\n",
       "3     False  False  False  False  False   False  False  False     False\n",
       "4     False  False  False  False  False   False  False  False     False\n",
       "..      ...    ...    ...    ...    ...     ...    ...    ...       ...\n",
       "519   False  False  False  False  False   False  False   True     False\n",
       "520   False  False   True  False  False   False  False   True     False\n",
       "521   False  False  False  False  False   False  False   True     False\n",
       "522   False  False  False  False  False   False  False   True     False\n",
       "523   False  False  False  False  False   False  False   True     False\n",
       "\n",
       "[524 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 참고. 썸을 안 쳤을 때는 이렇게 나옴 \n",
    "X_test.isna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age 컬럼 (train 157, test 106 결측) \n",
    "# age는 탑승자의 나이를 의미하고, survived와 상관관계가 낮으므로 컬럼을 삭제 \n",
    "\n",
    "# 결측일 조건 \n",
    "cond_na = X_train['age'].isna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=-0.03894154189837849, pvalue=0.32990878593933864)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 피어슨 상관계수 | pearsonr( , ) = (상관계수, p-Value) | 유의수준 5%에서 귀무가설 기각 \n",
    "# ; 여기서 p-Value가 0.05 보다 크므로 유의하지 않다. | 상관관계도 적은데다가 음수 \n",
    "# ; 물결 '~'는 '포함되어있지않으면'. \n",
    "\n",
    "from scipy.stats import pearsonr \n",
    "\n",
    "pearsonr(y_train['survived'][~cond_na], X_train['age'][~cond_na]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완료 후 age 컬럼을 삭제 \n",
    "# drop에서 컬럼 날릴 때 axis=1 | drop에서 row 날릴 때 axis=0 \n",
    "\n",
    "X_train = X_train.drop('age', axis=1) \n",
    "X_test = X_test.drop('age', axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fare 컬럼 (train 1 결측) \n",
    "# ; fare는 티켓요금을 의미하고 train에만 결측치가 1개 존재하므로 레코드를 삭제함 \n",
    "\n",
    "# 결측일 조건 \n",
    "cond_na = X_train['fare'].isna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행 삭제 \n",
    "# 결측이 아닌 걸로 정의 \n",
    "\n",
    "X_train = X_train[~cond_na] \n",
    "y_train = y_train[~cond_na] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cabin 컬럼 (train 614, test 400 결측)\n",
    "# cabin은 선실번호를 의미하고 train은 레코드의 78%, test는 레코드의 76%가 결측이므로 컬럼을 삭제 \n",
    "\n",
    "# cabin 컬럼을 삭제 \n",
    "X_train = X_train.drop('cabin', axis=1) \n",
    "X_test = X_test.drop('cabin', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embarked 컬럼 (train1, test1 결측) \n",
    "# embarked는 탑승한 곳을 의미하고, 범주형으로 (C, Q, S 中) '최다빈도'를 가지는 범주로 '대체'함 \n",
    "\n",
    "# 최다빈도 \n",
    "# ; value_counts-시리즈 값이 정수, 문자열, 카테고리 값인 경우 각각 값이 나온 횟수 \n",
    "# ; idxmax- 데이터프레임 내 값 중, 최고값의 인덱스 위치 리턴  \n",
    "# ; idxmin- \" \" 최소값의 \" \" \n",
    "\n",
    "top = X_train['embarked'].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대치 \n",
    "# 누락된 데이터(NaN) 채우기 - 괄호 안의 top으로(최다빈도) 채우기 \n",
    "X_train['embarked'] = X_train['embarked'].fillna(top) \n",
    "X_test['embarked'] = X_test['embarked'].fillna(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex           3\n",
      "ticket      621\n",
      "embarked      3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# @ Step3-3. (3)카테고리형 컬럼 전처리 | 카테고리형(숫자형이 아닌 것)\n",
    "# 문자열(object) 컬럼들의 유일값 수 확인 \n",
    "\n",
    "# ; select_dtypes: 특정 데이터(object)만 호출하기 \n",
    "# ; unique: 유일한 값. 고유값 찾기 | 유일값이란?(:데이터에 있는 고유값)\n",
    "# ; nunique: 데이터 고유값들의 수 출력 (중복값 제외하고 산출) (MC 분류수 산출) \n",
    "\n",
    "print(X_train.select_dtypes('object').nunique())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex           3\n",
      "ticket      445\n",
      "embarked      3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_test.select_dtypes('object').nunique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      517\n",
       "female    244\n",
       "F          23\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (카테고리형 컬럼 확인 시) 특이한 것, 문제가 있는 것 처리 \n",
    "\n",
    "# (sex 컬럼) - 여성에 대한 일부 카테고리가 'F'로 되어있음 \n",
    "\n",
    "X_train['sex'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      325\n",
       "female    173\n",
       "F          26\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['sex'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train,test 내 (sex 컬럼)의 'F'를 'female'로 통일 (replace)\n",
    "\n",
    "X_train['sex'] = X_train['sex'].map({'male':'male', 'female':'female', 'F':'female'}) \n",
    "X_test['sex'] = X_test['sex'].map({'male':'male', 'female':'female', 'F':'female'}) \n",
    "\n",
    "# map함수 이용하지 않을 경우는, for반복문 이용해서 일일이 하나하나 리스트에 접근해서 계산해서 하나씩 또 append 해줘야 하는데, \n",
    "# map함수 이용하면, 요소에 적용한 함수 하나만 넘겨주면 알아서 자동적으로 리스트를 함수에 적용해서 map객체를 리턴  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ticket 컬럼) \n",
    "# 대다수가 중복되지 않으므로 컬럼을 삭제하는 것으로 결정 -> 어느 한 MC로 그룹핑이 안되고 특징이 없다는 뜻. \n",
    "\n",
    "X_train = X_train.drop('ticket', axis=1) \n",
    "X_test = X_test.drop('ticket', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-4. (4)수치형 컬럼 전처리 \n",
    "\n",
    "# pclass 컬럼\n",
    "# 수치형으로 인식되지만 1,2,3등석 정보를 각 1,2,3으로 저장한 것으로 \n",
    "# 카테고리의 의미를 가지는 컬럼 (즉, 문자가, 문자가 아닌 숫자 형태로 되어있음)\n",
    "\n",
    "# dtype 변경 후 파생변수 pclass_gp에 할당하고 기존 컬럼 삭제 \n",
    "# ; astype: 열의 요소의 dtype(데이터타입) 변경 \n",
    "\n",
    "X_train['pclass'] = X_train['pclass'].astype('object') \n",
    "X_test['pclass'] = X_test['pclass'].astype('object') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완료 후 삭제 \n",
    "X_train = X_train.drop('pclass', axis=1) \n",
    "X_test = X_test.drop('pclass', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (sibsp, parch 컬럼) | (sib는 형제, sp는 배우자 수) (par는 부모, ch는 자녀 수) \n",
    "# sibsp는 동승한 형제 또는 배우자의 수, parch는 동승한 부모 또는 자녀의 수이므로 \n",
    "# 두 컬럼을 합한 파생변수 fam을 생성하고, 이는 동승한 가족 인원을 의미 \n",
    "\n",
    "X_train['fam'] = X_train['sibsp'] + X_train['parch'] \n",
    "X_test['fam'] = X_test['sibsp'] + X_test['parch'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완료 후 삭제 \n",
    "\n",
    "X_train = X_train.drop(['sibsp','parch'], axis=1) \n",
    "X_test = X_test.drop(['sibsp','parch'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-5. (5)데이터 분할 : 문제에 주어진 train데이터를 train과 valid로 분할하여 X_TRAIN과 X_VAL, y_TRAIN과 y_VAL에 각각 할당한다. (valid: 유효한, 타당한) \n",
    "# train데이터를 train과 valid로 분할(X와 y에서). (@) 따라서 X_test를 이렇게 나눈건 없다(x).\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# X_train과 y_train을 학습용과 검증용으로 분할 \n",
    "# 학습용(X_TRAIN, y_TRAIN), 검증용(X_VAL, y_VAL) \n",
    "\n",
    "X_TRAIN, X_VAL, y_TRAIN, y_VAL = train_test_split(X_train, y_train, random_state=1234, test_size=0.1)\n",
    "\n",
    "# random_state: 세트를 섞을 때 해당 int값 보고 섞음. 하이퍼파라미터 튜닝 시 이 값을 고정해주고 튜닝해야 매번 데이터셋이 변경되는 것 방지 가능.\n",
    "# (random_state은 난수값 고정이고, 어떤 숫자적 의미는 아님)\n",
    "# test_size: 테스트셋 구성의 비율. 0.1은 전체 데이터셋의 10%를 테스트셋으로 지정하겠다는 의미 (default는 0.25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(705, 4)\n"
     ]
    }
   ],
   "source": [
    "# 분할 후 shape 확인 \n",
    "# shape: 넘피 numpy 배열에서, 배열의 형태를 알아보는 함수. 배열의 형태를 튜플로 반환. (행 , 열)\n",
    "\n",
    "print(X_TRAIN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_VAL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(705, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_TRAIN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_VAL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-6. (6)인코딩 \n",
    "# 카테고리형 컬럼에 대해 원-핫 인코딩 수행 \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "# OneHotEncoder: y타겟이 숫자 의미 갖지 않도록 바꿔줌. (데이터의, 거리 정보 없애는데 사용)\n",
    "# (e.g.) 1-> 1001 , 2-> 0100 , 3-> 0010 , 4->0001\n",
    "# OneHotEncoder를 함으로써, 변환된 결과는, numpy.array로. 이를 데이터프레임으로 변환하는 과정이 필요하다.  \n",
    "\n",
    "\n",
    "# 인코딩 할 카테고리형 컬럼만 별도 저장 (사본 저장) \n",
    "X_TRAIN_category = X_TRAIN.select_dtypes('object').copy()\n",
    "X_VAL_category = X_VAL.select_dtypes('object').copy() \n",
    "\n",
    "X_TEST_category = X_test.select_dtypes('object').copy() #소문자\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코딩 \n",
    "\n",
    "enc = OneHotEncoder(sparse=False).fit(X_TRAIN_category)\n",
    "\n",
    "# fit메서드: 훈련하라. 모델을 학습시킬 때 사용. 머신러닝이 데이터에 머신러닝 모델을 맞추는 것(fit) -> fit에서 평균, 표준편차 등 구하고. \n",
    "# sparse(드문,희박한)는, sparse=True가 디폴트. sparse=True면 Matrix 리턴. sparse=False면 array 리턴. \n",
    "\n",
    "# transform: fit을 통해 세운 기준으로 맞춰서 변형하는 함수 \n",
    "\n",
    "X_TRAIN_OH = enc.transform(X_TRAIN_category)\n",
    "X_VAL_OH = enc.transform(X_VAL_category)\n",
    "\n",
    "X_TEST_OH = enc.transform(X_TEST_category) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# □ 데이터 인코딩 : 사이킷런 머신러닝(ML) 알고리즘은, 입력데이터에 문자열 값을 허용하지 않아, 문자열을 숫자형으로 변환하는 과정이 필요 \n",
    "# (encoding ; 정보의 형태나 형식을 변환하는 처리 또는 처리 형식)\n",
    "# 카테고리형인 문자열은 인코딩을 통해 코드값인 숫자형으로 변환할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-7. (7)스케일링 (; 카테고리형이 아닌 숫자 관련된 것)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# StandardScaler: 표준화. 평균이 0이고 분산이 1인 정규분포 만드는 것. Z-score. \n",
    "\n",
    "# 스케일링 할 컬럼만 별도 저장. 사본 저장\n",
    "# select_dtype() 메소드의 exclude 옵션은 해당 dtype을 제외한 모든 dtype을 추출할 때 사용. \n",
    "\n",
    "X_TRAIN_conti=  X_TRAIN.select_dtypes(exclude='object').copy() \n",
    "X_VAL_conti =  X_VAL.select_dtypes(exclude='object').copy() \n",
    "\n",
    "X_TEST_conti =  X_test.select_dtypes(exclude='object').copy()  #소문자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN 데이터 기준으로 스케일링함 \n",
    "\n",
    "scale = StandardScaler().fit(X_TRAIN_conti) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-점수 표준화 \n",
    "\n",
    "X_TRAIN_STD = scale.transform(X_TRAIN_conti) \n",
    "X_VAL_STD = scale.transform(X_VAL_conti) \n",
    "\n",
    "X_TEST_STD = scale.transform(X_TEST_conti) \n",
    "\n",
    "# transform에서 평균,분산,표준편차 등 가지고,  거기에 때리면서 구하면서 표준화. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-8. (8)입력 데이터셋 준비  (*y는 타겟이니까 인코딩/스케일링 안한 것)\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "# 인코딩과 스케일링 된 넘파이 배열 연결  \n",
    "X_TRAIN = np.concatenate([X_TRAIN_OH, X_TRAIN_STD], axis=1)    \n",
    "X_VAL = np.concatenate([X_VAL_OH, X_VAL_STD], axis=1) \n",
    "\n",
    "# concatenate(잇다. 연결하다. 연관시키다) : \n",
    "# concatenate메서드: 선택한 축(axis) 방향으로 배열을 연결하는 메서드 (#axis=1이면 열 방향)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1차원 넘파이 배열로 '평탄화' (*y를)\n",
    "\n",
    "y_TRAIN = y_TRAIN.values.ravel() \n",
    "y_VAL = y_VAL.values.ravel() \n",
    "\n",
    "# (참고) 딕셔너리는 key(키), value(값). \n",
    "# 그 중 키만 뽑을 때 -> key()\n",
    "# 값만 뽑을 때 -> value() \n",
    "# 키,값 쌍으로 뽑고 싶을 때 -> items() \n",
    "\n",
    "# ravel: 1차원 배열로 평평하게 펴주는 함수. (y가 2차원 이상일거라서 1차원으로 펴준 것) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Ⅳ.모델학습) \n",
    "# 모형 후보군: Random Forest , XGBoost , LightGBM \n",
    "\n",
    "# Step4. 모델학습 (\"분류\"알고리즘이니 클래서파이로 임포트)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from xgboost import XGBRFClassifier \n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step4-1. (1) Random Forest \n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=500, max_depth=3, min_samples_leaf=10, max_features='sqrt', random_state=2022) \n",
    "\n",
    "# 모델학습\n",
    "model_rf = rf.fit(X_TRAIN,y_TRAIN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lhlh0\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "c:\\Users\\lhlh0\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# @ Step4-2. (2) XGBoost \n",
    "\n",
    "xgb = XGBRFClassifier(max_depth=8, n_estimators=500, nthread=5, min_child_weight=20, gamma=0.5, objective='binary:logistic', use_label_encoder=False, random_state=2022)\n",
    "\n",
    "# 모델학습\n",
    "model_xgb = xgb.fit(X_TRAIN,y_TRAIN,eval_metric='mlogloss')\n",
    "\n",
    "# eval: 평가하다. metric: 미터법. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step4-3. (3) LightGBM \n",
    "\n",
    "lgb = LGBMClassifier(max_depth=8, n_estimators=500, n_jobs=30, min_child_weight=10, learning_rate=0.2, objective='binary', random_state=2022)\n",
    "\n",
    "# 모델학습\n",
    "model_lgb = lgb.fit(X_TRAIN,y_TRAIN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step4-4. 성능평가 (기준: f1-score)를 통한 모델 선정 \n",
    "# 분류 알고리즘 사용, 모형 앙상블 \n",
    "# f1-score: 머신러닝 분류모델 평가 | 분류 성능 0 ~ 1 | 높을수록, 1에 가까울수록 좋은 모델\n",
    "# f1-score는 Precision(정밀도)과 Recall(재현율)의 조화평균(역수의 산술평균의 역수)으로, 주로 분류클래스 간 데이터 불균형이 심각할 때 사용.   \n",
    "\n",
    "from sklearn.metrics import f1_score   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증용 데이터셋을 통한 예측 \n",
    "# 참고로 X_VAL과 y_VAL은, 데이터셋 전처리 단계 중 데이터 분할 스텝에서, 데이터 분할을 학습용과 검증용으로 한 것 (검증용임) \n",
    "\n",
    "pred_rf = model_rf.predict(X_VAL) \n",
    "pred_xgb = model_xgb.predict(X_VAL) \n",
    "pred_lgb = model_lgb.predict(X_VAL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# f1-score 계산 \n",
    "\n",
    "f1_rf = f1_score(y_VAL,pred_rf) \n",
    "print(f1_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "f1_xgb = f1_score(y_VAL, pred_xgb)\n",
    "print(f1_xgb)\n",
    "\n",
    "# 교재는 0.625 정도 나옴 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6792452830188679\n"
     ]
    }
   ],
   "source": [
    "f1_lgb = f1_score(y_VAL, pred_lgb)\n",
    "print(f1_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 단계로, 결과를 제출하기 위한 코드를 작성. \n",
    "# f1-score를 기준으로 Random Forest를 최종 모형으로 선정하고, 평가데이터를 통해 결과를 예측하고, 이를 문제에서 요구하는 형식으로 제출 \n",
    "\n",
    "# Ⅴ.결과제출  @ Step5. 결과 제출하기 \n",
    "# 실제 시험에서 답 제출 시 성능이 가장 우수한 모형 하나만 구현 (배열 연결과 똑같이 하되 Test로)\n",
    "\n",
    "# (e.g.) X1, X2, X3, X4, X5 中, X1을 따로 떼어서 원핫인코딩 수행하고, X2~X5는 표준화 하고 표준편차 구함 \n",
    "# 분리해서 작업했었어서 나중에 concatenate으로 합쳐준 것. 한번에 퉁으로 했으면 합쳐줄 필요없었을텐데\n",
    "\n",
    "X_TEST = np.concatenate([X_TEST_OH, X_TEST_STD], axis=1) \n",
    "\n",
    "y_pred = model_rf.predict(X_TEST) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# □ 데이터 인코딩 : 사이킷런 머신러닝(ML) 알고리즘은, 입력데이터에 문자열 값을 허용하지 않아, 문자열을 숫자형으로 변환하는 과정이 필요 \n",
    "# (encoding ; 정보의 형태나 형식을 변환하는 처리 또는 처리 형식)\n",
    "# 카테고리형인 문자열은 인코딩을 통해 코드값인 숫자형으로 변환할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제에서 요구하는 형태로 변환 필요 \n",
    "\n",
    "obj = {'ID':ID, 'survived':y_pred} \n",
    "\n",
    "# 딕셔너리{key:value} 생성 \n",
    "# series는 1차원 | Data Frame은 2차원 \n",
    "\n",
    "result = pd.DataFrame(obj) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하위에 12345.csv 이름으로 저장하기 \n",
    "\n",
    "result.to_csv(\"12345_csv\", index=False) # 인덱스를 포함하지 않는 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 시험 환경에서 제출하는 최종 제출 코드는 위의 단계에서 필요한 부분만을 선볗하여 제출하면 됨 \n",
    "# 번외로, 실제 시험은 제출하고 끝이지만. 연습 결과 채점 위한 평가 진행 \n",
    "\n",
    "# Ⅵ. 채점 모델 평가  @ Step6. 채점 모델 평가 (번외)\n",
    "# 실제값 \n",
    "\n",
    "actual = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\01회\\titanic3_y_test.csv', encoding='cp949')\n",
    "actual = actual['survived'].ravel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6884422110552764"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 채점 기준이 될 성과지표 값 \n",
    "\n",
    "f1_score(actual, y_pred)\n",
    "\n",
    "# 교재는 0.7083으로 됨 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mo. 2-1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (문제 ①) USArrests 데이터셋을 불러와, UrbanPop이 60 이상인 지역 중 Murder와 Assault의 합 대비 Assault의 비율이 0.05 이상인 레코드 수를 구하여라. \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "exam1 = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\02회\\USArrests.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Murder와 Assault의 합 대비 Assault의 비율에 대한 컬럼 생성 \n",
    "\n",
    "# Murder와 Assault의 합\n",
    "exam1['MA'] = exam1['Murder'] + exam1['Assault'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Murder와 Assault의 합 대비 Assault의 비율\n",
    "\n",
    "exam1['ratio'] = exam1['Assault']/exam1['MA'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UrbanPop이 60 이상이고, ratio가 0.05 이상인 경우 \n",
    "\n",
    "cond = (exam1['UrbanPop']>=60) & (exam1['ratio']>=0.05) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당 \n",
    "\n",
    "result = exam1[cond].shape[0] \n",
    "\n",
    "# 셰입0은 행수(레코드수), 셰입하고 각진 괄호!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력 \n",
    "\n",
    "print(result) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mo. 2-1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (문제 ②) swiss 데이터셋을 불러와, Fertility 컬럼에 대해서 내림차순으로 정렬한 후 정렬한 데이터를 기준으로 홀수번째 레코드들의 평균에서 짝수번째 레코드들의 평균을 뺀 값을 구하여라. \n",
    "# (단, 첫번째 행에 있는 데이터를 1번으로 하고, 결과는 소수점 넷째 자리에서 반올림하여 표현) \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "exam2 = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\02회\\swiss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fertility 컬럼에 대해서 내림차순으로 정렬 \n",
    "\n",
    "sort = exam2['Fertility'].sort_values(ascending=False, ignore_index=True) \n",
    "# ascending=False 내림차순, ignore_index=True 기존 인덱스 무시 \n",
    "# (참고)ascend:올라가다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     92.5\n",
      "1     92.4\n",
      "2     92.2\n",
      "3     87.1\n",
      "4     85.8\n",
      "5     83.8\n",
      "6     83.1\n",
      "7     82.9\n",
      "8     82.4\n",
      "9     80.2\n",
      "10    79.4\n",
      "11    79.3\n",
      "12    77.6\n",
      "13    77.3\n",
      "14    76.9\n",
      "15    76.1\n",
      "16    75.5\n",
      "17    74.2\n",
      "18    72.7\n",
      "19    72.5\n",
      "20    72.0\n",
      "21    71.7\n",
      "22    70.5\n",
      "23    70.4\n",
      "24    69.3\n",
      "25    68.9\n",
      "26    68.3\n",
      "27    67.6\n",
      "28    66.9\n",
      "29    65.7\n",
      "30    65.5\n",
      "31    65.4\n",
      "32    65.1\n",
      "33    65.0\n",
      "34    65.0\n",
      "35    64.4\n",
      "36    64.1\n",
      "37    61.7\n",
      "38    60.5\n",
      "39    58.3\n",
      "40    57.4\n",
      "41    56.6\n",
      "42    55.7\n",
      "43    54.3\n",
      "44    44.7\n",
      "45    42.8\n",
      "46    35.0\n",
      "Name: Fertility, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 홀수번째와 짝수번째 행 번호 생성 \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "idx = np.arange(1,48) \n",
    "# 1이상 48미만 [1,2,3 ... 47]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n"
     ]
    }
   ],
   "source": [
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 홀수 \n",
    "\n",
    "odd = (idx % 2 == 1) \n",
    "# 여기서 %는 나누고 나서 나머지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 짝수 \n",
    "\n",
    "even = (idx % 2 == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차이 \n",
    "\n",
    "diff = sort[odd].mean() - sort[even].mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당 \n",
    "\n",
    "result = round(diff,3) \n",
    "\n",
    "# 반올림. 소수점 3째 셋째 '까지' 반올림. (즉, 넷째 자리에서 반올림) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.453\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력 \n",
    "\n",
    "print(result) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mo. 2-1-3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (문제 ③) CO2 데이터셋을 불러와, Type컬럼이 Mississippi이면서 conc컬럼에서 백의 자리 또는 일의 자리가 5인 경우 레코드들의 수를 구하여라. \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "exam3 =  pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\02회\\CO2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>conc</th>\n",
       "      <th>uptake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quebec</td>\n",
       "      <td>nonchilled</td>\n",
       "      <td>95</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quebec</td>\n",
       "      <td>nonchilled</td>\n",
       "      <td>175</td>\n",
       "      <td>30.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quebec</td>\n",
       "      <td>nonchilled</td>\n",
       "      <td>250</td>\n",
       "      <td>34.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quebec</td>\n",
       "      <td>nonchilled</td>\n",
       "      <td>350</td>\n",
       "      <td>37.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quebec</td>\n",
       "      <td>nonchilled</td>\n",
       "      <td>500</td>\n",
       "      <td>35.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>chilled</td>\n",
       "      <td>250</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>chilled</td>\n",
       "      <td>350</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>chilled</td>\n",
       "      <td>500</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>chilled</td>\n",
       "      <td>675</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>chilled</td>\n",
       "      <td>1000</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Type   Treatment  conc  uptake\n",
       "0        Quebec  nonchilled    95    16.0\n",
       "1        Quebec  nonchilled   175    30.4\n",
       "2        Quebec  nonchilled   250    34.8\n",
       "3        Quebec  nonchilled   350    37.2\n",
       "4        Quebec  nonchilled   500    35.3\n",
       "..          ...         ...   ...     ...\n",
       "79  Mississippi     chilled   250    17.9\n",
       "80  Mississippi     chilled   350    17.9\n",
       "81  Mississippi     chilled   500    17.9\n",
       "82  Mississippi     chilled   675    18.9\n",
       "83  Mississippi     chilled  1000    19.9\n",
       "\n",
       "[84 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quebec          40\n",
       "Mississippi     40\n",
       " Quebec          1\n",
       "quebec           1\n",
       "Mississi/ppi     1\n",
       "Mis/sissippi     1\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam3['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### case 1. Type컬럼이 Mississippi인 경우 \n",
    "# 'Mississi/ppi'와 'Mis/sissippi'이 섞여 있음 \n",
    "# exam3['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '/'를 제거 \n",
    "\n",
    "exam3['Type'] = exam3['Type'].str.replace('/','') \n",
    "\n",
    "# 여기서, str은 문자열 string 의미하고, replace는 교환대체 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mississippi일 조건 \n",
    "\n",
    "case1 = (exam3['Type'] == 'Mississippi') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### case2. conc컬럼에서 백의 자리 또는 일의 자리가 5인 경우 \n",
    "\n",
    "# 백의 자리가 5인 경우 \n",
    "\n",
    "hundred = exam3['conc']//100 == 5 \n",
    "\n",
    "# //는 몫 구하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일의 자리가 5인 경우 \n",
    "\n",
    "one = exam3['conc'].astype('string').str.endswith('5') \n",
    "\n",
    "# 다른 방법. 숫자면, %5 == 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 조건을 만족하는 조건 \n",
    "\n",
    "case2 = hundred | one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 result에 할당 \n",
    "\n",
    "result = exam3[case1 & case2].shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력 \n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mo. 2-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [작업형 제2유형] \n",
    "# (문제 Ⅱ) 아래는 블랙프라이데이 제품 구매자들의 구매 정보에 관련한 데이터의 일부이다. 주어진 데이터를 이용하여 예측 모형을 만들고 아래에 따라 CSV 파일을 생성하시오. \n",
    "# (문제 조건) (\"회귀 알고리즘 사용\") 성능이 우수한 예측모형을 구축하기 위해서는 적절한 데이터 전처리, Feature Engineering, \"회귀 알고리즘\" 사용, 초매개변수 최적화, 모형 앙상블 등이 수반되어야 한다. \n",
    "# (제출형식) User_ID | Purchase \n",
    "\n",
    "# Ⅰ.데이터셋 불러오기  Ⅱ.데이터셋 확인하기  Ⅲ.데이터셋 전처리  Ⅳ.모델학습  Ⅴ.결과제출  Ⅵ.채점모델평가  \n",
    "# \"Ⅲ.데이터셋 전처리\" - (1)불필요한 컬럼 삭제  (2)결측치 처리  (3)카테고리형 컬럼 전처리  (4)수치형 컬럼 전처리 \n",
    "# (5)데이터 분할  (6)인코딩  (7)스케일링  (8)입력 데이터셋 준비  \n",
    "\n",
    "# MAE (Mean Absolute Error) 평균 절대 오차. 예측 오차 절대값들의 평균 -> \"낮을 수록 좋다\" \n",
    "# MSE (Mean Squared Error) 평균 제곱 오차. 예측 오차 제곱합들의 평균\n",
    "# RMSE (Root Mean Squared Error) 평균 제곱근 오차. MSE의 제곱근 값 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Ⅰ.데이터셋 불러오기) Step1. | 데이터셋 불러오기 \n",
    "\n",
    "import pandas as pd \n",
    "X_train = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\02회\\BlackFriday_X_train.csv') \n",
    "X_test = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\02회\\BlackFriday_X_test.csv')\n",
    "y_train = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\02회\\BlackFriday_y_train.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   User_ID Product_ID Gender    Age  Occupation City_Category  \\\n",
      "0  1001889  P00166642      M  18-25          14             B   \n",
      "1  1003320  P00030842      M  26-35           1             B   \n",
      "2  1003690   P0095742      M  18-25           0             B   \n",
      "3  1002796  P00227642      M  26-35          14             B   \n",
      "4  1001671  P00114542      M  36-45           0             B   \n",
      "\n",
      "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
      "0                          2               0                   8   \n",
      "1                          1               1                   1   \n",
      "2                          2               0                   4   \n",
      "3                          3               0                   1   \n",
      "4                          2               0                   5   \n",
      "\n",
      "   Product_Category_2  Product_Category_3  \n",
      "0                 NaN                 NaN  \n",
      "1                 2.0                15.0  \n",
      "2                 5.0                 NaN  \n",
      "3                 5.0                14.0  \n",
      "4                 NaN                 NaN  \n"
     ]
    }
   ],
   "source": [
    "# (Ⅱ.데이터셋 확인하기) Step2. | 데이터셋 확인하기 \n",
    "\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   User_ID Product_ID Gender    Age  Occupation City_Category  \\\n",
      "0  1004079  P00194042      M  36-45          17             B   \n",
      "1  1000936  P00320942      M  18-25           4             C   \n",
      "2  1000238  P00117242      F  51-55           7             B   \n",
      "3  1005250  P00354142      M  51-55           6             B   \n",
      "4  1005281  P00152742      M  26-35           2             A   \n",
      "\n",
      "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
      "0                          3               1                   8   \n",
      "1                         4+               0                   1   \n",
      "2                          0               0                   8   \n",
      "3                         4+               1                   6   \n",
      "4                          2               0                   5   \n",
      "\n",
      "   Product_Category_2  Product_Category_3  \n",
      "0                11.0                 NaN  \n",
      "1                 4.0                 9.0  \n",
      "2                17.0                 NaN  \n",
      "3                 8.0                 NaN  \n",
      "4                 NaN                 NaN  \n"
     ]
    }
   ],
   "source": [
    "print(X_test.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   User_ID  Purchase\n",
      "0  1001889      7802\n",
      "1  1003320     15412\n",
      "2  1003690      1448\n",
      "3  1002796      3927\n",
      "4  1001671      7091\n"
     ]
    }
   ],
   "source": [
    "print(y_train.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3900 entries, 0 to 3899\n",
      "Data columns (total 11 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   User_ID                     3900 non-null   int64  \n",
      " 1   Product_ID                  3900 non-null   object \n",
      " 2   Gender                      3900 non-null   object \n",
      " 3   Age                         3900 non-null   object \n",
      " 4   Occupation                  3900 non-null   int64  \n",
      " 5   City_Category               3900 non-null   object \n",
      " 6   Stay_In_Current_City_Years  3900 non-null   object \n",
      " 7   Marital_Status              3900 non-null   int64  \n",
      " 8   Product_Category_1          3900 non-null   int64  \n",
      " 9   Product_Category_2          2695 non-null   float64\n",
      " 10  Product_Category_3          1213 non-null   float64\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 335.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Step 2-2. | 데이터셋 요약 정보 확인 ; 오브젝트는 문자형임\n",
    "\n",
    "print(X_train.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2600 entries, 0 to 2599\n",
      "Data columns (total 11 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   User_ID                     2600 non-null   int64  \n",
      " 1   Product_ID                  2600 non-null   object \n",
      " 2   Gender                      2600 non-null   object \n",
      " 3   Age                         2600 non-null   object \n",
      " 4   Occupation                  2600 non-null   int64  \n",
      " 5   City_Category               2600 non-null   object \n",
      " 6   Stay_In_Current_City_Years  2600 non-null   object \n",
      " 7   Marital_Status              2600 non-null   int64  \n",
      " 8   Product_Category_1          2600 non-null   int64  \n",
      " 9   Product_Category_2          1752 non-null   float64\n",
      " 10  Product_Category_3          793 non-null    float64\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 223.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X_test.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3900 entries, 0 to 3899\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   User_ID   3900 non-null   int64\n",
      " 1   Purchase  3900 non-null   int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 61.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(y_train.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            User_ID   Occupation  Marital_Status  Product_Category_1  \\\n",
      "count  3.900000e+03  3900.000000     3900.000000         3900.000000   \n",
      "mean   1.002986e+06     7.980513        0.420000            5.273846   \n",
      "std    1.711858e+03     6.562434        0.493622            3.710045   \n",
      "min    1.000002e+06     0.000000        0.000000            1.000000   \n",
      "25%    1.001501e+06     2.000000        0.000000            1.000000   \n",
      "50%    1.003046e+06     7.000000        0.000000            5.000000   \n",
      "75%    1.004386e+06    14.000000        1.000000            8.000000   \n",
      "max    1.006040e+06    20.000000        1.000000           18.000000   \n",
      "\n",
      "       Product_Category_2  Product_Category_3  \n",
      "count         2695.000000         1213.000000  \n",
      "mean             9.852319           12.663644  \n",
      "std              5.058134            4.057423  \n",
      "min              2.000000            3.000000  \n",
      "25%              5.000000            9.000000  \n",
      "50%              9.000000           14.000000  \n",
      "75%             15.000000           16.000000  \n",
      "max             18.000000           18.000000  \n"
     ]
    }
   ],
   "source": [
    "# Step 2-3. | 기초통계량 확인 \n",
    "\n",
    "print(X_train.describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            User_ID   Occupation  Marital_Status  Product_Category_1  \\\n",
      "count  2.600000e+03  2600.000000     2600.000000         2600.000000   \n",
      "mean   1.002952e+06     8.061154        0.403846            5.359231   \n",
      "std    1.718149e+03     6.525626        0.490762            3.769651   \n",
      "min    1.000001e+06     0.000000        0.000000            1.000000   \n",
      "25%    1.001406e+06     2.000000        0.000000            2.000000   \n",
      "50%    1.003012e+06     7.000000        0.000000            5.000000   \n",
      "75%    1.004385e+06    14.000000        1.000000            8.000000   \n",
      "max    1.006037e+06    20.000000        1.000000           18.000000   \n",
      "\n",
      "       Product_Category_2  Product_Category_3  \n",
      "count         1752.000000          793.000000  \n",
      "mean             9.748288           12.813367  \n",
      "std              5.080618            4.098900  \n",
      "min              2.000000            4.000000  \n",
      "25%              5.000000            9.000000  \n",
      "50%              9.000000           15.000000  \n",
      "75%             15.000000           16.000000  \n",
      "max             18.000000           18.000000  \n"
     ]
    }
   ],
   "source": [
    "print(X_test.describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            User_ID      Purchase\n",
      "count  3.900000e+03   3900.000000\n",
      "mean   1.002986e+06   9394.564615\n",
      "std    1.711858e+03   5039.666976\n",
      "min    1.000002e+06    373.000000\n",
      "25%    1.001501e+06   5841.750000\n",
      "50%    1.003046e+06   8062.500000\n",
      "75%    1.004386e+06  12162.750000\n",
      "max    1.006040e+06  23942.000000\n"
     ]
    }
   ],
   "source": [
    "print(y_train.describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Ⅲ.데이터셋 전처리\" - (1)불필요한 컬럼 삭제  (2)결측치 처리  (3)카테고리형 컬럼 전처리  (4)수치형 컬럼 전처리 \n",
    "# (5)데이터 분할  (6)인코딩  (7)스케일링  (8)입력 데이터셋 준비  \n",
    "\n",
    "# (Ⅲ.데이터셋 전처리) @ Step3. 데이터셋 전처리 \n",
    "\n",
    "# Step3-1. (1)불필요한 컬럼 삭제 : 데이터셋으로부터 User_ID, Product_ID 컬럼을 삭제한다. \n",
    " \n",
    "# User_ID 컬럼은 탑승자에 대한 고유 정보로 key 역할로 모델에는 불필요함 \n",
    "\n",
    "# 결과 제출 시에는 X_test의 ID컬럼이 필요하기 때문에 별도 저장 \n",
    "\n",
    "User_ID = X_test['User_ID'].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product_ID는 제품의 고유 ID로 마찬가지로 삭제함 \n",
    "\n",
    "# 데이터들에서 User_ID, Product_ID 컬럼 삭제 \n",
    "\n",
    "X_train = X_train.drop(columns = ['User_ID' , 'Product_ID']) \n",
    "\n",
    "X_test = X_test.drop(columns = ['User_ID' , 'Product_ID']) \n",
    "\n",
    "y_train = y_train.drop(columns = 'User_ID') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                           0\n",
       "Age                              0\n",
       "Occupation                       0\n",
       "City_Category                    0\n",
       "Stay_In_Current_City_Years       0\n",
       "Marital_Status                   0\n",
       "Product_Category_1               0\n",
       "Product_Category_2            1205\n",
       "Product_Category_3            2687\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3-2. (2)결측치 처리 \n",
    "# : Train, Test 양쪽의 결측치를 확인하고, 결측치의 수 등을 기준으로 열을 삭제함 \n",
    "\n",
    "# 결측치 확인 \n",
    "X_train.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                           0\n",
       "Age                              0\n",
       "Occupation                       0\n",
       "City_Category                    0\n",
       "Stay_In_Current_City_Years       0\n",
       "Marital_Status                   0\n",
       "Product_Category_1               0\n",
       "Product_Category_2             848\n",
       "Product_Category_3            1807\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인 \n",
    "X_test.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product_Category_2 컬럼 (train 1205, test 848 결측) \n",
    "# train은 레코드의 31%, test는 레코드의 33%가 결측이고, Product_Category_1의 하위 카테고리 \n",
    "# 컬럼을 삭제 \n",
    "\n",
    "X_train = X_train.drop('Product_Category_2', axis=1) \n",
    "X_test = X_test.drop('Product_Category_2', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product_Category_3 컬럼 (train 2687, test 1807 결측) \n",
    "# train은 레코드의 69%, test는 레코드의 70%가 결측이고, Product_Category_1,2의 하위 카테고리 \n",
    "# 컬럼을 삭제 \n",
    "\n",
    "X_train = X_train.drop('Product_Category_3', axis=1) \n",
    "X_test = X_test.drop('Product_Category_3', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-3. (3)카테고리형 컬럼 전처리 | 카테고리형(숫자형이 아닌 것)\n",
    "\n",
    "# 문자열(object) 컬럼들의 유일값 수 확인 \n",
    "\n",
    "# ; select_dtypes: 특정 데이터(object)만 호출하기 \n",
    "# ; unique: 유일한 값. 고유값 찾기 | 유일값이란?(:데이터에 있는 고유값)\n",
    "# ; nunique: 데이터 고유값들의 수 출력 (중복값 제외하고 산출) (MC 분류수 산출) \n",
    "\n",
    "# 컬럼별 카테고리 확인 결과 큰 이상 없음 ~~!! (여기서는)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender                        2\n",
      "Age                           7\n",
      "City_Category                 3\n",
      "Stay_In_Current_City_Years    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.select_dtypes('object').nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender                        2\n",
      "Age                           7\n",
      "City_Category                 3\n",
      "Stay_In_Current_City_Years    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_test.select_dtypes('object').nunique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Occupation  Marital_Status  Product_Category_1\n",
      "0             14               0                   8\n",
      "1              1               1                   1\n",
      "2              0               0                   4\n",
      "3             14               0                   1\n",
      "4              0               0                   5\n",
      "...          ...             ...                 ...\n",
      "3895           2               0                   1\n",
      "3896           0               0                  11\n",
      "3897           4               0                   8\n",
      "3898          16               0                   1\n",
      "3899          12               0                  16\n",
      "\n",
      "[3900 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# @ Step3-4. (4)수치형 컬럼 전처리 //////\n",
    "\n",
    "print(X_train.select_dtypes(exclude='object')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Occupation  Marital_Status  Product_Category_1\n",
      "0             17               1                   8\n",
      "1              4               0                   1\n",
      "2              7               0                   8\n",
      "3              6               1                   6\n",
      "4              2               0                   5\n",
      "...          ...             ...                 ...\n",
      "2595           0               0                   5\n",
      "2596          14               0                   1\n",
      "2597           9               0                   8\n",
      "2598           4               1                   6\n",
      "2599          18               1                  11\n",
      "\n",
      "[2600 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_test.select_dtypes(exclude='object')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Occupation,  Marital_Status,  Product_Category_1 컬럼 \n",
    "\n",
    "# 수치형으로 인식되지만, 카테고리의 의미를 가지는 컬럼 (즉, 문자가, 문자가 아닌 숫자 형태로 되어있음)\n",
    "\n",
    "# dtype 변경 후 파생변수 OCC_gp, Matrial_gp, PC_gp에 할당하고 기존 컬럼 삭제 \n",
    "# ; astype: 열의 요소의 dtype(데이터타입) 변경 \n",
    "\n",
    "X_train['OCC_gp'] = X_train['Occupation'].astype('object') \n",
    "X_test['OCC_gp'] = X_test['Occupation'].astype('object') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Matrial_gp'] = X_train['Marital_Status'].astype('object') \n",
    "X_test['Matrial_gp'] = X_test['Marital_Status'].astype('object') \n",
    "\n",
    "X_train['PC_gp'] = X_train['Product_Category_1'].astype('object') \n",
    "X_test['PC_gp'] = X_test['Product_Category_1'].astype('object') \n",
    "\n",
    "# 모의고사1에서는 각각 데이터타입 변경 완료 후 삭제해주는 작업을 매번 했었는데, 2장에서는 한번에 하려고 함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 컬럼 삭제  (한꺼번에 실행)\n",
    "\n",
    "X_train = X_train.drop(['Occupation', 'Marital_Status', 'Product_Category_1'], axis=1) \n",
    "X_test = X_test.drop(['Occupation', 'Marital_Status', 'Product_Category_1'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-5. (5)데이터 분할 : 문제에 주어진 train데이터를 train과 valid로 분할하여 X_TRAIN과 X_VAL, y_TRAIN과 y_VAL에 각각 할당한다. (valid: 유효한, 타당한) \n",
    "# train데이터를 train과 valid로 분할(X와 y에서). (@) 따라서 X_test를 이렇게 나눈건 없다(x).\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# X_train과 y_train을 학습용과 검증용으로 분할 \n",
    "# 학습용(X_TRAIN, y_TRAIN), 검증용(X_VAL, y_VAL) \n",
    "\n",
    "X_TRAIN, X_VAL, y_TRAIN, y_VAL = train_test_split(X_train, y_train, random_state=1234, test_size=0.3) \n",
    "# (모의1에서는 test_size 0.1로 했었음) \n",
    "\n",
    "# random_state: 세트를 섞을 때 해당 int값 보고 섞음. 하이퍼파라미터 튜닝 시 이 값을 고정해주고 튜닝해야 매번 데이터셋이 변경되는 것 방지 가능.\n",
    "# (random_state은 난수값 고정이고, 어떤 숫자적 의미는 아님)\n",
    "# test_size: 테스트셋 구성의 비율. 0.1은 전체 데이터셋의 10%를 테스트셋으로 지정하겠다는 의미 (default는 0.25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2730, 7)\n"
     ]
    }
   ],
   "source": [
    "# 분할 후 shape 확인 \n",
    "# shape: 넘피 numpy 배열에서, 배열의 형태를 알아보는 함수. 배열의 형태를 튜플로 반환. (행 , 열)\n",
    "\n",
    "print(X_TRAIN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1170, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_VAL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2730, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_TRAIN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1170, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_VAL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-6. (6)인코딩 \n",
    "# 카테고리형 컬럼에 대해 원-핫 인코딩 수행 \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "# OneHotEncoder: y타겟이 숫자 의미 갖지 않도록 바꿔줌. (데이터의, 거리 정보 없애는데 사용)\n",
    "# (e.g.) 1-> 1001 , 2-> 0100 , 3-> 0010 , 4->0001\n",
    "# OneHotEncoder를 함으로써, 변환된 결과는, numpy.array로. 이를 데이터프레임으로 변환하는 과정이 필요하다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩 할 카테고리형 컬럼만 별도 저장 (사본 저장) \n",
    "X_TRAIN_category = X_TRAIN.select_dtypes('object').copy()\n",
    "X_VAL_category = X_VAL.select_dtypes('object').copy() \n",
    "\n",
    "X_TEST_category = X_test.select_dtypes('object').copy() #소문자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코딩 \n",
    "\n",
    "enc = OneHotEncoder(sparse=False).fit(X_TRAIN_category)\n",
    "\n",
    "# fit메서드: 훈련하라. 모델을 학습시킬 때 사용. 머신러닝이 데이터에 머신러닝 모델을 맞추는 것(fit) -> fit에서 평균, 표준편차 등 구하고. \n",
    "# sparse(드문,희박한)는, sparse=True가 디폴트. sparse=True면 Matrix 리턴. sparse=False면 array 리턴. \n",
    "\n",
    "# transform: fit을 통해 세운 기준으로 맞춰서 변형하는 함수 \n",
    "\n",
    "X_TRAIN_OH = enc.transform(X_TRAIN_category)\n",
    "X_VAL_OH = enc.transform(X_VAL_category)\n",
    "\n",
    "X_TEST_OH = enc.transform(X_TEST_category) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-7. (7)스케일링 (; 카테고리형이 아닌 숫자 관련된 것)\n",
    "\n",
    "# -> 여기서는, 스케일링 할 컬럼이 없으므로 생략 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step3-8. (8)입력 데이터셋 준비  (*y는 타겟이니까 인코딩/스케일링 안한 것)\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "# 인코딩과 스케일링 된 넘파이 배열 연결  \n",
    "#(모의1) X_TRAIN = np.concatenate([X_TRAIN_OH, X_TRAIN_STD], axis=1)    \n",
    "#(모의1) X_VAL = np.concatenate([X_VAL_OH, X_VAL_STD], axis=1) \n",
    "\n",
    "# concatenate(잇다. 연결하다. 연관시키다) : \n",
    "# concatenate메서드: 선택한 축(axis) 방향으로 배열을 연결하는 메서드 (#axis=1이면 열 방향)\n",
    "\n",
    "\n",
    "# 인코딩과 스케일링 된 넘파이 배열 연결  (모의2: 스케일링 생략으로, 모의1 보다 간단히 셋)\n",
    "X_TRAIN = X_TRAIN_OH    \n",
    "X_VAL = X_VAL_OH  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1차원 넘파이 배열로 '평탄화' (*y를)\n",
    "\n",
    "y_TRAIN = y_TRAIN.values.ravel() \n",
    "y_VAL = y_VAL.values.ravel() \n",
    "\n",
    "# (참고) 딕셔너리는 key(키), value(값). \n",
    "# 그 중 키만 뽑을 때 -> key()\n",
    "# 값만 뽑을 때 -> value() \n",
    "# 키,값 쌍으로 뽑고 싶을 때 -> items() \n",
    "\n",
    "# ravel: 1차원 배열로 평평하게 펴주는 함수. (y가 2차원 이상일거라서 1차원으로 펴준 것) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Ⅳ.모델학습) \n",
    "# 모형 후보군: Random Forest , XGBoost , LightGBM \n",
    "\n",
    "# Step4. 모델학습 (\"회귀\" 알고리즘 이니까 클래서파이가 아닌, 리그레서로 임포트)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRFRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step4-1. (1) Random Forest \n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=500, max_depth=3, min_samples_leaf=10, max_features=2, random_state=2022) \n",
    "\n",
    "# 모델학습\n",
    "model_rf = rf.fit(X_TRAIN,y_TRAIN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step4-2. (2) XGBoost \n",
    "\n",
    "xgb = XGBRFRegressor(max_depth=8, n_estimators=500, nthread=5, min_child_weight=20, gamma=0.5, objective='reg:squarederror', use_label_encoder=False, random_state=2022)\n",
    "\n",
    "# 모델학습 (모의2)\n",
    "#(모의1) model_xgb = xgb.fit(X_TRAIN,y_TRAIN,eval_metric='mlogloss')\n",
    "\n",
    "model_xgb = xgb.fit(X_TRAIN,y_TRAIN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step4-3. (3) LightGBM \n",
    "\n",
    "lgb = LGBMRegressor(max_depth=8, n_estimators=500, n_jobs=30, min_child_weight=10, learning_rate=0.2, objective='regression', random_state=2022)\n",
    "\n",
    "# 모델학습\n",
    "model_lgb = lgb.fit(X_TRAIN,y_TRAIN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Step4-4. 성능평가 (기준: MAE)를 통한 모델 선정 \n",
    "# 회귀 알고리즘 사용, 모형 앙상블 \n",
    "\n",
    "# MAE (Mean Absolute Error) 평균 절대 오차. 예측 오차 절대값들의 평균 -> \"낮을 수록 좋다\"  \n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증용 데이터셋을 통한 예측 \n",
    "# 참고로 X_VAL과 y_VAL은, 데이터셋 전처리 단계 중 데이터 분할 스텝에서, 데이터 분할을 학습용과 검증용으로 한 것 (검증용임) \n",
    "\n",
    "pred_rf = model_rf.predict(X_VAL) \n",
    "pred_xgb = model_xgb.predict(X_VAL) \n",
    "pred_lgb = model_lgb.predict(X_VAL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3890.5911682476026\n"
     ]
    }
   ],
   "source": [
    "# MAE 계산 \n",
    "\n",
    "mae_rf = mean_absolute_error(y_VAL,pred_rf) \n",
    "print(mae_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2536.4782616770167\n"
     ]
    }
   ],
   "source": [
    "mae_xgb = mean_absolute_error(y_VAL, pred_xgb)\n",
    "print(mae_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2523.4959648495173\n"
     ]
    }
   ],
   "source": [
    "mae_lgb = mean_absolute_error(y_VAL, pred_lgb)\n",
    "print(mae_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 단계로, 결과를 제출하기 위한 코드를 작성. \n",
    "# MAE를 기준으로 LightGBM을 최종 모형으로 선정하고, 평가데이터를 통해 결과를 예측하고, 이를 문제에서 요구하는 형식으로 제출 \n",
    "\n",
    "# Ⅴ.결과제출  @ Step5. 결과 제출하기 \n",
    "# 실제 시험에서 답 제출 시 성능이 가장 우수한 모형 하나만 구현 (배열 연결과 똑같이 하되 Test로)\n",
    "\n",
    "# (모의1) \n",
    "# X_TEST = np.concatenate([X_TEST_OH, X_TEST_STD], axis=1) \n",
    "# y_pred = model_rf.predict(X_TEST) \n",
    "\n",
    "#(모의2)\n",
    "X_TEST = X_TEST_OH \n",
    "y_pred = model_lgb.predict(X_TEST)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# □ 데이터 인코딩 : 사이킷런 머신러닝(ML) 알고리즘은, 입력데이터에 문자열 값을 허용하지 않아, 문자열을 숫자형으로 변환하는 과정이 필요 \n",
    "# (encoding ; 정보의 형태나 형식을 변환하는 처리 또는 처리 형식)\n",
    "# 카테고리형인 문자열은 인코딩을 통해 코드값인 숫자형으로 변환할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제에서 요구하는 형태로 변환 필요 \n",
    "\n",
    "obj = {'User_ID':User_ID, 'Purchase':y_pred} \n",
    "\n",
    "# 딕셔너리{key:value} 생성 \n",
    "# series는 1차원 | Data Frame은 2차원 \n",
    "\n",
    "result = pd.DataFrame(obj) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하위에 67890.csv 이름으로 저장하기 \n",
    "\n",
    "result.to_csv(\"67890_csv\", index=False) # 인덱스를 포함하지 않는 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 시험 환경에서 제출하는 최종 제출 코드는 위의 단계에서 필요한 부분만을 선볗하여 제출하면 됨 \n",
    "# 번외로, 실제 시험은 제출하고 끝이지만. 연습 결과 채점 위한 평가 진행 \n",
    "\n",
    "# Ⅵ. 채점 모델 평가  @ Step6. 채점 모델 평가 (번외)\n",
    "# 실제값 \n",
    "\n",
    "actual = pd.read_csv(r'C:\\빅데이터분석기사 실기 모의고사\\data\\모의고사\\02회\\BlackFriday_y_test.csv', encoding='cp949')\n",
    "actual = actual['Purchase'].ravel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2556.0031980180756"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 채점 기준이 될 성과지표 값 \n",
    "\n",
    "mean_absolute_error(actual, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9bf15b9dd490fd4628809ac77023ed1d989990ba58b472ec013d0bafd3a285da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
